{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/2d-convolution-using-python-numpy-43442ff5f381\n",
    "# https://github.com/macbuse/macbuse.github.io/blob/master/PROG/convolve.py\n",
    "def convolve2D(image: np.ndarray, kernel: np.ndarray, mode = \"valid\", correlation = False):\n",
    "    # Cross correlation or Convolution depends on the orientation of the kernel\n",
    "    kernel = kernel if correlation else np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    # Gather shapes of kernel + image + padding\n",
    "    x_kernel_size, y_kernel_size = kernel.shape\n",
    "    x_image_size, y_image_size = image.shape[0:2]\n",
    "\n",
    "    if mode == \"valid\":\n",
    "        # Ouput matrix size of a full convolution\n",
    "        x_output = int(x_image_size - x_kernel_size + 1)\n",
    "        y_output = int(y_image_size - y_kernel_size + 1)\n",
    "        output = np.zeros((x_output, y_output))\n",
    "\n",
    "        for y in range(0, y_image_size - y_kernel_size + 1):\n",
    "            for x in range(0, x_image_size - x_kernel_size + 1):\n",
    "                output[x, y] = (kernel * image[x: x + x_kernel_size, y: y + y_kernel_size]).sum()\n",
    "    \n",
    "    elif mode == \"full\":\n",
    "        # Output matrix size of a valid convolution\n",
    "        x_output = int((x_image_size + x_kernel_size - 1))\n",
    "        y_output = int((y_image_size + y_kernel_size - 1))\n",
    "        image_padded = np.pad(image, x_kernel_size - 1, mode='constant', constant_values=(0))\n",
    "        output = np.zeros((x_output, y_output))\n",
    "\n",
    "        for x in range(0, output.shape[0]):\n",
    "            for y in range(0, output.shape[1]):\n",
    "                output[x, y] = (kernel * image_padded[x: x + x_kernel_size, y: y + y_kernel_size]).sum()\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1x1 filter\n",
    "\n",
    "kernel = np.array([[1]])\n",
    "\n",
    "# 2x2 filter\n",
    "kernel = np.array([[1, 0], [1, 0]])\n",
    "\n",
    "# 3x3 filter\n",
    "# kernel = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])\n",
    "\n",
    "# 4x4 filter\n",
    "# kernel = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1]])\n",
    "\n",
    "# Ascending 3x3 matrix\n",
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Ascending 5x5 matrix\n",
    "# a = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]])\n",
    "\n",
    "b = convolve2D(a, kernel, mode = 'valid', correlation = True)\n",
    "utils.display_images([a, kernel, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # TODO: return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # TODO: update params and return input gradient\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # Update params and return input gradient\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return np.dot(self.weights.T, output_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(self.input)\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.multiply(output_gradient, self.activation_prime(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Activation):\n",
    "    def __init__(self):\n",
    "        tanh = lambda x: np.tanh(x)\n",
    "        tanh_prime = lambda x: 1 - np.tanh(x)**2\n",
    "        super().__init__(tanh, tanh_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, input):\n",
    "        tmp = np.exp(input)\n",
    "        self.output = tmp / np.sum(tmp)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        n = np.size(self.output)\n",
    "        tmp = np.tile(self.output, n)\n",
    "        return np.dot(tmp * (np.identity(n) - np.transpose(tmp)), output_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth # number of kernels\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size) # multiple 3D kernels\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases)\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                # self.output[i] += signal.correlate2d(self.input[j], self.kernels[i][j], \"valid\")\n",
    "                self.output[i] += convolve2D(self.input[j], self.kernels[i, j])\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        kernels_gradient = np.zeros(self.kernels_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                kernels_gradient[i, j] = convolve2D(self.input[j], output_gradient[i], \"valid\", correlation = True)\n",
    "                input_gradient[j] += convolve2D(output_gradient[i], self.kernels[i, j], \"full\")\n",
    "        \n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "        return input_gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Layer):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return np.reshape(input, self.output_shape)\n",
    "    \n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return np.reshape(output_gradient, self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        def sigmoid_prime(x):\n",
    "            s = sigmoid(x)\n",
    "            return s * (1 - s)\n",
    "            \n",
    "        super().__init__(sigmoid, sigmoid_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def binary_cross_entropy_prime(y_true, y_pred):\n",
    "    return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / np.size(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR-problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape([[0,0], [0,1], [1,0], [1,1]], (4, 2, 1))\n",
    "Y = np.reshape([[0], [1], [1], [0]], (4, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "    Dense(2, 3),\n",
    "    Tanh(),\n",
    "    Dense(3, 1),\n",
    "    Tanh()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, error: 0.4734077373432598\n",
      "Epoch 1, error: 0.4197199483866649\n",
      "Epoch 2, error: 0.4061687561408821\n",
      "Epoch 3, error: 0.39241196714882665\n",
      "Epoch 4, error: 0.37900146914534266\n",
      "Epoch 5, error: 0.3672012639320885\n",
      "Epoch 6, error: 0.3574406795135354\n",
      "Epoch 7, error: 0.34915887559166225\n",
      "Epoch 8, error: 0.3416796328513097\n",
      "Epoch 9, error: 0.3345790742515749\n",
      "Epoch 10, error: 0.3276451428067785\n",
      "Epoch 11, error: 0.3207995149176902\n",
      "Epoch 12, error: 0.31404829194250616\n",
      "Epoch 13, error: 0.3074500342369214\n",
      "Epoch 14, error: 0.3010913008261342\n",
      "Epoch 15, error: 0.29506584926904456\n",
      "Epoch 16, error: 0.28945734930302114\n",
      "Epoch 17, error: 0.28432707683768754\n",
      "Epoch 18, error: 0.27970784227488804\n",
      "Epoch 19, error: 0.2756040584808127\n",
      "Epoch 20, error: 0.2719964016613555\n",
      "Epoch 21, error: 0.2688487828293907\n",
      "Epoch 22, error: 0.2661155228118095\n",
      "Epoch 23, error: 0.2637473650857362\n",
      "Epoch 24, error: 0.26169578268802335\n",
      "Epoch 25, error: 0.25991562791224865\n",
      "Epoch 26, error: 0.25836646611035907\n",
      "Epoch 27, error: 0.2570130010459468\n",
      "Epoch 28, error: 0.2558249452972894\n",
      "Epoch 29, error: 0.2547765958656467\n",
      "Epoch 30, error: 0.2538462859080899\n",
      "Epoch 31, error: 0.2530158145020151\n",
      "Epoch 32, error: 0.25226990907603153\n",
      "Epoch 33, error: 0.25159574545506375\n",
      "Epoch 34, error: 0.2509825331850606\n",
      "Epoch 35, error: 0.25042116454602065\n",
      "Epoch 36, error: 0.24990392126996747\n",
      "Epoch 37, error: 0.2494242313668295\n",
      "Epoch 38, error: 0.24897646833109366\n",
      "Epoch 39, error: 0.24855578559061917\n",
      "Epoch 40, error: 0.2481579799349807\n",
      "Epoch 41, error: 0.2477793785942784\n",
      "Epoch 42, error: 0.24741674551740336\n",
      "Epoch 43, error: 0.24706720317340966\n",
      "Epoch 44, error: 0.24672816685779989\n",
      "Epoch 45, error: 0.24639728903135097\n",
      "Epoch 46, error: 0.24607241166435415\n",
      "Epoch 47, error: 0.24575152491801805\n",
      "Epoch 48, error: 0.24543273078135808\n",
      "Epoch 49, error: 0.245114210508968\n",
      "Epoch 50, error: 0.24479419488384946\n",
      "Epoch 51, error: 0.2444709364696343\n",
      "Epoch 52, error: 0.24414268312653456\n",
      "Epoch 53, error: 0.24380765215286995\n",
      "Epoch 54, error: 0.24346400448652505\n",
      "Epoch 55, error: 0.243109818466093\n",
      "Epoch 56, error: 0.24274306271903137\n",
      "Epoch 57, error: 0.24236156782556595\n",
      "Epoch 58, error: 0.2419629965178838\n",
      "Epoch 59, error: 0.24154481233567365\n",
      "Epoch 60, error: 0.2411042469007459\n",
      "Epoch 61, error: 0.2406382663358395\n",
      "Epoch 62, error: 0.24014353789067733\n",
      "Epoch 63, error: 0.2396163986241156\n",
      "Epoch 64, error: 0.23905282911588796\n",
      "Epoch 65, error: 0.23844843675164135\n",
      "Epoch 66, error: 0.2377984552502156\n",
      "Epoch 67, error: 0.23709776986303804\n",
      "Epoch 68, error: 0.23634098105951062\n",
      "Epoch 69, error: 0.23552252329791468\n",
      "Epoch 70, error: 0.23463685905302464\n",
      "Epoch 71, error: 0.2336787703611709\n",
      "Epoch 72, error: 0.23264376854544155\n",
      "Epoch 73, error: 0.23152863420016034\n",
      "Epoch 74, error: 0.2303320798691576\n",
      "Epoch 75, error: 0.2290554936222089\n",
      "Epoch 76, error: 0.22770367283836696\n",
      "Epoch 77, error: 0.22628540167354622\n",
      "Epoch 78, error: 0.2248136824301291\n",
      "Epoch 79, error: 0.223305430743378\n",
      "Epoch 80, error: 0.22178051712990285\n",
      "Epoch 81, error: 0.220260190222056\n",
      "Epoch 82, error: 0.21876511261614726\n",
      "Epoch 83, error: 0.21731339823138407\n",
      "Epoch 84, error: 0.21591907555377732\n",
      "Epoch 85, error: 0.21459128221982987\n",
      "Epoch 86, error: 0.21333427328736154\n",
      "Epoch 87, error: 0.21214810109603768\n",
      "Epoch 88, error: 0.21102968875616562\n",
      "Epoch 89, error: 0.20997400151053902\n",
      "Epoch 90, error: 0.2089750907061257\n",
      "Epoch 91, error: 0.208026889434253\n",
      "Epoch 92, error: 0.2071237320287063\n",
      "Epoch 93, error: 0.2062606302708504\n",
      "Epoch 94, error: 0.2054333664067273\n",
      "Epoch 95, error: 0.20463846625319265\n",
      "Epoch 96, error: 0.20387310582953333\n",
      "Epoch 97, error: 0.20313499062430562\n",
      "Epoch 98, error: 0.2024222328214029\n",
      "Epoch 99, error: 0.2017332407728694\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    error = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        # Forward pass\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "        \n",
    "        # Calculate error\n",
    "        error += mse(y, output)\n",
    "\n",
    "        # Backward pass\n",
    "        grad = mse_prime(y, output)\n",
    "        \n",
    "        for layer in reversed(network):\n",
    "            grad = layer.backward(grad, learning_rate)\n",
    "        \n",
    "    error /= len(X)\n",
    "    print(f\"Epoch {epoch}, error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype('float32') / 255\n",
    "    y = np_utils.to_categorical(y)\n",
    "    y = y.reshape(len(y), 2, 1)\n",
    "    return x, y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 100)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, error: 0.3842429981766866\n",
      "Epoch 1, error: 0.0904590681185435\n",
      "Epoch 2, error: 0.08087092308807678\n",
      "Epoch 3, error: 0.04212235551378086\n",
      "Epoch 4, error: 0.03797345861954363\n",
      "Epoch 5, error: 0.012140596749584322\n",
      "Epoch 6, error: 0.01009384670026201\n",
      "Epoch 7, error: 0.010154601586890872\n",
      "Epoch 8, error: 0.007422624155806277\n",
      "Epoch 9, error: 0.0064671668470632215\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 1, actual: 1\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n",
      "Predicted: 0, actual: 0\n"
     ]
    }
   ],
   "source": [
    "network = [\n",
    "    Convolutional((1, 28, 28), 3, 5),\n",
    "    Sigmoid(),\n",
    "    Reshape((5, 26, 26), (5 * 26 * 26, 1)),\n",
    "    Dense(5 * 26 * 26, 100),\n",
    "    Sigmoid(),\n",
    "    Dense(100, 2),\n",
    "    Sigmoid()\n",
    "]\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    error = 0\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        # Forward pass\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "        \n",
    "        # Calculate error\n",
    "        error += binary_cross_entropy(y, output)\n",
    "\n",
    "        # Backward pass\n",
    "        grad = binary_cross_entropy_prime(y, output)\n",
    "        \n",
    "        for layer in reversed(network):\n",
    "            grad = layer.backward(grad, learning_rate)\n",
    "    \n",
    "    error /= len(x_train)\n",
    "    print(f\"Epoch {epoch}, error: {error}\")\n",
    "\n",
    "for x, y in zip(x_test, y_test):\n",
    "    output = x\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    print(f\"Predicted: {np.argmax(output)}, actual: {np.argmax(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe975d092d2ac7f937a42acc0742499e035d25a93da4137fa8ab0db54717d31f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
