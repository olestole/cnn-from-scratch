{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-advisory",
   "metadata": {},
   "source": [
    "**Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broken-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-robinson",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-sensitivity",
   "metadata": {},
   "source": [
    "**Nodes in each layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 5\n",
    "hidden_1_nodes = 3\n",
    "hidden_2_nodes = 5\n",
    "output_nodes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-classics",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-advantage",
   "metadata": {},
   "source": [
    "**Inputs and true outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cathedral-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14],\n",
       "       [0.95],\n",
       "       [0.48],\n",
       "       [0.15],\n",
       "       [0.72]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 100, size = (input_nodes, 1)) / 100\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0], [1], [0], [0]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-philip",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-mills",
   "metadata": {},
   "source": [
    "**Defining Activation functions and loss with their derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-hunger",
   "metadata": {},
   "source": [
    "Sigmoid for first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "western-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_dash(x):\n",
    "    return sig(x) * (1 - sig(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-affairs",
   "metadata": {},
   "source": [
    "Softmax for second hidden layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minor-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_dash(x):\n",
    "    \n",
    "    I = np.eye(x.shape[0])\n",
    "    \n",
    "    return softmax(x) * (I - softmax(x).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-reference",
   "metadata": {},
   "source": [
    "Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "synthetic-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E(y_true, y_pred):\n",
    "    # Make sure not to take log(0)\n",
    "    return -np.sum(y_true * np.log(y_pred + 10**-100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "macro-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E_grad(y_true, y_pred):\n",
    "    # Make sure not to divide by 0\n",
    "    return -y_true/(y_pred + 10**-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-willow",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-congo",
   "metadata": {},
   "source": [
    "**Random initialization of weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adjacent-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.random(size = (hidden_1_nodes, input_nodes))\n",
    "b1 = np.zeros(shape = (hidden_1_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vulnerable-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = np.random.random(size = (hidden_2_nodes, hidden_1_nodes))\n",
    "b2 = np.zeros(shape = (hidden_2_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "commercial-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "w3 = np.random.random(size = (output_nodes, hidden_2_nodes))\n",
    "b3 = np.zeros(shape = (output_nodes, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-happiness",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-packing",
   "metadata": {},
   "source": [
    "**Forward feed before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "perfect-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.34017024],\n",
       "       [ 5.43156321],\n",
       "       [-1.18273918],\n",
       "       [-1.18380015]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat\n",
    "in_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "curious-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ruled-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038190828454768505"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-riding",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-delaware",
   "metadata": {},
   "source": [
    "**SGD Momentum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standard-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a93706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65102442, 0.54272134, 0.11560211, 0.53425941, 0.39725919],\n",
       "       [0.15174371, 0.66676445, 0.05897222, 0.73428985, 0.94896598],\n",
       "       [0.04318962, 1.06806175, 0.62971541, 0.67037589, 0.05681751]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "clean-samuel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_w1 = np.zeros(w1.shape)\n",
    "\n",
    "update_b1 = np.zeros(b1.shape)\n",
    "\n",
    "update_w2 = np.zeros(w2.shape)\n",
    "\n",
    "update_b2 = np.zeros(b2.shape)\n",
    "\n",
    "update_w3 = np.zeros(w3.shape)\n",
    "\n",
    "update_b3 = np.zeros(b3.shape)\n",
    "\n",
    "update_w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-visitor",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff04a8",
   "metadata": {},
   "source": [
    "**Total number of epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e869d04",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-parking",
   "metadata": {},
   "source": [
    "**Backpropagation in ANNs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "experimental-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training is 0.000418344493096532 -- epoch number 1\n",
      "\n",
      "\n",
      "loss before training is 0.00041829767070975996 -- epoch number 2\n",
      "\n",
      "\n",
      "loss before training is 0.0004182508588032948 -- epoch number 3\n",
      "\n",
      "\n",
      "loss before training is 0.000418204057373803 -- epoch number 4\n",
      "\n",
      "\n",
      "loss before training is 0.0004181572664177289 -- epoch number 5\n",
      "\n",
      "\n",
      "loss before training is 0.00041811048593151683 -- epoch number 6\n",
      "\n",
      "\n",
      "loss before training is 0.00041806371591172214 -- epoch number 7\n",
      "\n",
      "\n",
      "loss before training is 0.00041801695635501135 -- epoch number 8\n",
      "\n",
      "\n",
      "loss before training is 0.0004179702072573845 -- epoch number 9\n",
      "\n",
      "\n",
      "loss before training is 0.0004179234686159524 -- epoch number 10\n",
      "\n",
      "\n",
      "loss before training is 0.00041787674042660395 -- epoch number 11\n",
      "\n",
      "\n",
      "loss before training is 0.0004178300226861167 -- epoch number 12\n",
      "\n",
      "\n",
      "loss before training is 0.00041778331539126824 -- epoch number 13\n",
      "\n",
      "\n",
      "loss before training is 0.0004177366185381697 -- epoch number 14\n",
      "\n",
      "\n",
      "loss before training is 0.0004176899321233765 -- epoch number 15\n",
      "\n",
      "\n",
      "loss before training is 0.00041764325614355503 -- epoch number 16\n",
      "\n",
      "\n",
      "loss before training is 0.00041759659059514967 -- epoch number 17\n",
      "\n",
      "\n",
      "loss before training is 0.00041754993547427164 -- epoch number 18\n",
      "\n",
      "\n",
      "loss before training is 0.0004175032907780316 -- epoch number 19\n",
      "\n",
      "\n",
      "loss before training is 0.00041745665650231857 -- epoch number 20\n",
      "\n",
      "\n",
      "loss before training is 0.00041741003264435445 -- epoch number 21\n",
      "\n",
      "\n",
      "loss before training is 0.00041736341920036135 -- epoch number 22\n",
      "\n",
      "\n",
      "loss before training is 0.00041731681616645044 -- epoch number 23\n",
      "\n",
      "\n",
      "loss before training is 0.0004172702235396214 -- epoch number 24\n",
      "\n",
      "\n",
      "loss before training is 0.0004172236413162076 -- epoch number 25\n",
      "\n",
      "\n",
      "loss before training is 0.0004171770694929865 -- epoch number 26\n",
      "\n",
      "\n",
      "loss before training is 0.00041713050806606924 -- epoch number 27\n",
      "\n",
      "\n",
      "loss before training is 0.0004170839570319002 -- epoch number 28\n",
      "\n",
      "\n",
      "loss before training is 0.0004170374163875902 -- epoch number 29\n",
      "\n",
      "\n",
      "loss before training is 0.0004169908861290282 -- epoch number 30\n",
      "\n",
      "\n",
      "loss before training is 0.00041694436625321383 -- epoch number 31\n",
      "\n",
      "\n",
      "loss before training is 0.00041689785675670264 -- epoch number 32\n",
      "\n",
      "\n",
      "loss before training is 0.00041685135763538353 -- epoch number 33\n",
      "\n",
      "\n",
      "loss before training is 0.0004168048688861453 -- epoch number 34\n",
      "\n",
      "\n",
      "loss before training is 0.0004167583905057653 -- epoch number 35\n",
      "\n",
      "\n",
      "loss before training is 0.000416711922490688 -- epoch number 36\n",
      "\n",
      "\n",
      "loss before training is 0.0004166654648373578 -- epoch number 37\n",
      "\n",
      "\n",
      "loss before training is 0.0004166190175419969 -- epoch number 38\n",
      "\n",
      "\n",
      "loss before training is 0.0004165725806016049 -- epoch number 39\n",
      "\n",
      "\n",
      "loss before training is 0.0004165261540127374 -- epoch number 40\n",
      "\n",
      "\n",
      "loss before training is 0.0004164797377717276 -- epoch number 41\n",
      "\n",
      "\n",
      "loss before training is 0.00041643333187490876 -- epoch number 42\n",
      "\n",
      "\n",
      "loss before training is 0.00041638693631916964 -- epoch number 43\n",
      "\n",
      "\n",
      "loss before training is 0.0004163405511009545 -- epoch number 44\n",
      "\n",
      "\n",
      "loss before training is 0.0004162941762168188 -- epoch number 45\n",
      "\n",
      "\n",
      "loss before training is 0.00041624781166320693 -- epoch number 46\n",
      "\n",
      "\n",
      "loss before training is 0.00041620145743667436 -- epoch number 47\n",
      "\n",
      "\n",
      "loss before training is 0.00041615511353410966 -- epoch number 48\n",
      "\n",
      "\n",
      "loss before training is 0.00041610877995173514 -- epoch number 49\n",
      "\n",
      "\n",
      "loss before training is 0.00041606245668599515 -- epoch number 50\n",
      "\n",
      "\n",
      "loss before training is 0.0004160161437337783 -- epoch number 51\n",
      "\n",
      "\n",
      "loss before training is 0.00041596984109141795 -- epoch number 52\n",
      "\n",
      "\n",
      "loss before training is 0.0004159235487553584 -- epoch number 53\n",
      "\n",
      "\n",
      "loss before training is 0.00041587726672271053 -- epoch number 54\n",
      "\n",
      "\n",
      "loss before training is 0.0004158309949893633 -- epoch number 55\n",
      "\n",
      "\n",
      "loss before training is 0.0004157847335520944 -- epoch number 56\n",
      "\n",
      "\n",
      "loss before training is 0.00041573848240768126 -- epoch number 57\n",
      "\n",
      "\n",
      "loss before training is 0.0004156922415527906 -- epoch number 58\n",
      "\n",
      "\n",
      "loss before training is 0.00041564601098342227 -- epoch number 59\n",
      "\n",
      "\n",
      "loss before training is 0.00041559979069657625 -- epoch number 60\n",
      "\n",
      "\n",
      "loss before training is 0.00041555358068902994 -- epoch number 61\n",
      "\n",
      "\n",
      "loss before training is 0.0004155073809566725 -- epoch number 62\n",
      "\n",
      "\n",
      "loss before training is 0.0004154611914963925 -- epoch number 63\n",
      "\n",
      "\n",
      "loss before training is 0.0004154150123049677 -- epoch number 64\n",
      "\n",
      "\n",
      "loss before training is 0.0004153688433789533 -- epoch number 65\n",
      "\n",
      "\n",
      "loss before training is 0.0004153226847147939 -- epoch number 66\n",
      "\n",
      "\n",
      "loss before training is 0.0004152765363090449 -- epoch number 67\n",
      "\n",
      "\n",
      "loss before training is 0.00041523039815826167 -- epoch number 68\n",
      "\n",
      "\n",
      "loss before training is 0.00041518427025922193 -- epoch number 69\n",
      "\n",
      "\n",
      "loss before training is 0.00041513815260814786 -- epoch number 70\n",
      "\n",
      "\n",
      "loss before training is 0.00041509204520203926 -- epoch number 71\n",
      "\n",
      "\n",
      "loss before training is 0.0004150459480372294 -- epoch number 72\n",
      "\n",
      "\n",
      "loss before training is 0.0004149998611103848 -- epoch number 73\n",
      "\n",
      "\n",
      "loss before training is 0.0004149537844181721 -- epoch number 74\n",
      "\n",
      "\n",
      "loss before training is 0.0004149077179569245 -- epoch number 75\n",
      "\n",
      "\n",
      "loss before training is 0.0004148616617237528 -- epoch number 76\n",
      "\n",
      "\n",
      "loss before training is 0.0004148156157146573 -- epoch number 77\n",
      "\n",
      "\n",
      "loss before training is 0.0004147695799265265 -- epoch number 78\n",
      "\n",
      "\n",
      "loss before training is 0.00041472355435580484 -- epoch number 79\n",
      "\n",
      "\n",
      "loss before training is 0.00041467753899949213 -- epoch number 80\n",
      "\n",
      "\n",
      "loss before training is 0.00041463153385358845 -- epoch number 81\n",
      "\n",
      "\n",
      "loss before training is 0.0004145855389150935 -- epoch number 82\n",
      "\n",
      "\n",
      "loss before training is 0.00041453955418034073 -- epoch number 83\n",
      "\n",
      "\n",
      "loss before training is 0.00041449357964655194 -- epoch number 84\n",
      "\n",
      "\n",
      "loss before training is 0.00041444761530939406 -- epoch number 85\n",
      "\n",
      "\n",
      "loss before training is 0.00041440166116642224 -- epoch number 86\n",
      "\n",
      "\n",
      "loss before training is 0.00041435571721374763 -- epoch number 87\n",
      "\n",
      "\n",
      "loss before training is 0.0004143097834478146 -- epoch number 88\n",
      "\n",
      "\n",
      "loss before training is 0.00041426385986562304 -- epoch number 89\n",
      "\n",
      "\n",
      "loss before training is 0.0004142179464637283 -- epoch number 90\n",
      "\n",
      "\n",
      "loss before training is 0.0004141720432383527 -- epoch number 91\n",
      "\n",
      "\n",
      "loss before training is 0.0004141261501866071 -- epoch number 92\n",
      "\n",
      "\n",
      "loss before training is 0.0004140802673047137 -- epoch number 93\n",
      "\n",
      "\n",
      "loss before training is 0.00041403439458967227 -- epoch number 94\n",
      "\n",
      "\n",
      "loss before training is 0.00041398853203792734 -- epoch number 95\n",
      "\n",
      "\n",
      "loss before training is 0.0004139426796459232 -- epoch number 96\n",
      "\n",
      "\n",
      "loss before training is 0.0004138968374106596 -- epoch number 97\n",
      "\n",
      "\n",
      "loss before training is 0.0004138510053281368 -- epoch number 98\n",
      "\n",
      "\n",
      "loss before training is 0.0004138051833960209 -- epoch number 99\n",
      "\n",
      "\n",
      "loss before training is 0.0004137593716098678 -- epoch number 100\n",
      "\n",
      "\n",
      "loss before training is 0.0004137135699667883 -- epoch number 101\n",
      "\n",
      "\n",
      "loss before training is 0.0004136677784636711 -- epoch number 102\n",
      "\n",
      "\n",
      "loss before training is 0.0004136219970965164 -- epoch number 103\n",
      "\n",
      "\n",
      "loss before training is 0.00041357622586254603 -- epoch number 104\n",
      "\n",
      "\n",
      "loss before training is 0.0004135304647579823 -- epoch number 105\n",
      "\n",
      "\n",
      "loss before training is 0.0004134847137799361 -- epoch number 106\n",
      "\n",
      "\n",
      "loss before training is 0.0004134389729246296 -- epoch number 107\n",
      "\n",
      "\n",
      "loss before training is 0.00041339324218872954 -- epoch number 108\n",
      "\n",
      "\n",
      "loss before training is 0.0004133475215689023 -- epoch number 109\n",
      "\n",
      "\n",
      "loss before training is 0.00041330181106192566 -- epoch number 110\n",
      "\n",
      "\n",
      "loss before training is 0.00041325611066468827 -- epoch number 111\n",
      "\n",
      "\n",
      "loss before training is 0.0004132104203728571 -- epoch number 112\n",
      "\n",
      "\n",
      "loss before training is 0.0004131647401844315 -- epoch number 113\n",
      "\n",
      "\n",
      "loss before training is 0.00041311907009507844 -- epoch number 114\n",
      "\n",
      "\n",
      "loss before training is 0.0004130734101017977 -- epoch number 115\n",
      "\n",
      "\n",
      "loss before training is 0.00041302776020125584 -- epoch number 116\n",
      "\n",
      "\n",
      "loss before training is 0.0004129821203897863 -- epoch number 117\n",
      "\n",
      "\n",
      "loss before training is 0.00041293649066472194 -- epoch number 118\n",
      "\n",
      "\n",
      "loss before training is 0.00041289087102195195 -- epoch number 119\n",
      "\n",
      "\n",
      "loss before training is 0.0004128452614588093 -- epoch number 120\n",
      "\n",
      "\n",
      "loss before training is 0.0004127996619711831 -- epoch number 121\n",
      "\n",
      "\n",
      "loss before training is 0.0004127540725564063 -- epoch number 122\n",
      "\n",
      "\n",
      "loss before training is 0.00041270849321114545 -- epoch number 123\n",
      "\n",
      "\n",
      "loss before training is 0.000412662923931734 -- epoch number 124\n",
      "\n",
      "\n",
      "loss before training is 0.0004126173647148385 -- epoch number 125\n",
      "\n",
      "\n",
      "loss before training is 0.0004125718155574588 -- epoch number 126\n",
      "\n",
      "\n",
      "loss before training is 0.00041252627645581703 -- epoch number 127\n",
      "\n",
      "\n",
      "loss before training is 0.0004124807474068021 -- epoch number 128\n",
      "\n",
      "\n",
      "loss before training is 0.0004124352284070805 -- epoch number 129\n",
      "\n",
      "\n",
      "loss before training is 0.0004123897194534299 -- epoch number 130\n",
      "\n",
      "\n",
      "loss before training is 0.000412344220542628 -- epoch number 131\n",
      "\n",
      "\n",
      "loss before training is 0.00041229873167078593 -- epoch number 132\n",
      "\n",
      "\n",
      "loss before training is 0.0004122532528351257 -- epoch number 133\n",
      "\n",
      "\n",
      "loss before training is 0.0004122077840322028 -- epoch number 134\n",
      "\n",
      "\n",
      "loss before training is 0.0004121623252586839 -- epoch number 135\n",
      "\n",
      "\n",
      "loss before training is 0.00041211687651101337 -- epoch number 136\n",
      "\n",
      "\n",
      "loss before training is 0.00041207143778608 -- epoch number 137\n",
      "\n",
      "\n",
      "loss before training is 0.00041202600908088347 -- epoch number 138\n",
      "\n",
      "\n",
      "loss before training is 0.00041198059039153514 -- epoch number 139\n",
      "\n",
      "\n",
      "loss before training is 0.0004119351817150348 -- epoch number 140\n",
      "\n",
      "\n",
      "loss before training is 0.0004118897830477158 -- epoch number 141\n",
      "\n",
      "\n",
      "loss before training is 0.0004118443943869111 -- epoch number 142\n",
      "\n",
      "\n",
      "loss before training is 0.0004117990157288432 -- epoch number 143\n",
      "\n",
      "\n",
      "loss before training is 0.0004117536470706228 -- epoch number 144\n",
      "\n",
      "\n",
      "loss before training is 0.0004117082884083612 -- epoch number 145\n",
      "\n",
      "\n",
      "loss before training is 0.00041166293973905825 -- epoch number 146\n",
      "\n",
      "\n",
      "loss before training is 0.00041161760105971375 -- epoch number 147\n",
      "\n",
      "\n",
      "loss before training is 0.00041157227236621673 -- epoch number 148\n",
      "\n",
      "\n",
      "loss before training is 0.00041152695365612244 -- epoch number 149\n",
      "\n",
      "\n",
      "loss before training is 0.0004114816449256532 -- epoch number 150\n",
      "\n",
      "\n",
      "loss before training is 0.00041143634617191985 -- epoch number 151\n",
      "\n",
      "\n",
      "loss before training is 0.00041139105739092257 -- epoch number 152\n",
      "\n",
      "\n",
      "loss before training is 0.00041134577858021655 -- epoch number 153\n",
      "\n",
      "\n",
      "loss before training is 0.00041130050973557983 -- epoch number 154\n",
      "\n",
      "\n",
      "loss before training is 0.0004112552508547897 -- epoch number 155\n",
      "\n",
      "\n",
      "loss before training is 0.00041121000193340213 -- epoch number 156\n",
      "\n",
      "\n",
      "loss before training is 0.0004111647629693054 -- epoch number 157\n",
      "\n",
      "\n",
      "loss before training is 0.00041111953395816663 -- epoch number 158\n",
      "\n",
      "\n",
      "loss before training is 0.0004110743148975408 -- epoch number 159\n",
      "\n",
      "\n",
      "loss before training is 0.00041102910578365043 -- epoch number 160\n",
      "\n",
      "\n",
      "loss before training is 0.0004109839066132731 -- epoch number 161\n",
      "\n",
      "\n",
      "loss before training is 0.00041093871738318645 -- epoch number 162\n",
      "\n",
      "\n",
      "loss before training is 0.0004108935380903904 -- epoch number 163\n",
      "\n",
      "\n",
      "loss before training is 0.0004108483687308851 -- epoch number 164\n",
      "\n",
      "\n",
      "loss before training is 0.00041080320930222573 -- epoch number 165\n",
      "\n",
      "\n",
      "loss before training is 0.00041075805980030143 -- epoch number 166\n",
      "\n",
      "\n",
      "loss before training is 0.0004107129202228895 -- epoch number 167\n",
      "\n",
      "\n",
      "loss before training is 0.00041066779056599014 -- epoch number 168\n",
      "\n",
      "\n",
      "loss before training is 0.00041062267082627 -- epoch number 169\n",
      "\n",
      "\n",
      "loss before training is 0.0004105775610006178 -- epoch number 170\n",
      "\n",
      "\n",
      "loss before training is 0.0004105324610860333 -- epoch number 171\n",
      "\n",
      "\n",
      "loss before training is 0.0004104873710790722 -- epoch number 172\n",
      "\n",
      "\n",
      "loss before training is 0.00041044229097617893 -- epoch number 173\n",
      "\n",
      "\n",
      "loss before training is 0.00041039722077424227 -- epoch number 174\n",
      "\n",
      "\n",
      "loss before training is 0.000410352160470373 -- epoch number 175\n",
      "\n",
      "\n",
      "loss before training is 0.00041030711006090467 -- epoch number 176\n",
      "\n",
      "\n",
      "loss before training is 0.000410262069542726 -- epoch number 177\n",
      "\n",
      "\n",
      "loss before training is 0.00041021703891239256 -- epoch number 178\n",
      "\n",
      "\n",
      "loss before training is 0.00041017201816745955 -- epoch number 179\n",
      "\n",
      "\n",
      "loss before training is 0.00041012700730337176 -- epoch number 180\n",
      "\n",
      "\n",
      "loss before training is 0.0004100820063177955 -- epoch number 181\n",
      "\n",
      "\n",
      "loss before training is 0.0004100370152070642 -- epoch number 182\n",
      "\n",
      "\n",
      "loss before training is 0.0004099920339682887 -- epoch number 183\n",
      "\n",
      "\n",
      "loss before training is 0.0004099470625981358 -- epoch number 184\n",
      "\n",
      "\n",
      "loss before training is 0.00040990210109282765 -- epoch number 185\n",
      "\n",
      "\n",
      "loss before training is 0.00040985714944969737 -- epoch number 186\n",
      "\n",
      "\n",
      "loss before training is 0.00040981220766552276 -- epoch number 187\n",
      "\n",
      "\n",
      "loss before training is 0.00040976727573663715 -- epoch number 188\n",
      "\n",
      "\n",
      "loss before training is 0.0004097223536600404 -- epoch number 189\n",
      "\n",
      "\n",
      "loss before training is 0.00040967744143273233 -- epoch number 190\n",
      "\n",
      "\n",
      "loss before training is 0.0004096325390512685 -- epoch number 191\n",
      "\n",
      "\n",
      "loss before training is 0.00040958764651187143 -- epoch number 192\n",
      "\n",
      "\n",
      "loss before training is 0.00040954276381231823 -- epoch number 193\n",
      "\n",
      "\n",
      "loss before training is 0.00040949789094849823 -- epoch number 194\n",
      "\n",
      "\n",
      "loss before training is 0.00040945302791785547 -- epoch number 195\n",
      "\n",
      "\n",
      "loss before training is 0.0004094081747167234 -- epoch number 196\n",
      "\n",
      "\n",
      "loss before training is 0.0004093633313418797 -- epoch number 197\n",
      "\n",
      "\n",
      "loss before training is 0.0004093184977903243 -- epoch number 198\n",
      "\n",
      "\n",
      "loss before training is 0.00040927367405850165 -- epoch number 199\n",
      "\n",
      "\n",
      "loss before training is 0.0004092288601436337 -- epoch number 200\n",
      "\n",
      "\n",
      "loss before training is 0.0004091840560421651 -- epoch number 201\n",
      "\n",
      "\n",
      "loss before training is 0.00040913926175120663 -- epoch number 202\n",
      "\n",
      "\n",
      "loss before training is 0.00040909447726698075 -- epoch number 203\n",
      "\n",
      "\n",
      "loss before training is 0.00040904970258693154 -- epoch number 204\n",
      "\n",
      "\n",
      "loss before training is 0.0004090049377071703 -- epoch number 205\n",
      "\n",
      "\n",
      "loss before training is 0.0004089601826249191 -- epoch number 206\n",
      "\n",
      "\n",
      "loss before training is 0.0004089154373369556 -- epoch number 207\n",
      "\n",
      "\n",
      "loss before training is 0.0004088707018400575 -- epoch number 208\n",
      "\n",
      "\n",
      "loss before training is 0.00040882597613044723 -- epoch number 209\n",
      "\n",
      "\n",
      "loss before training is 0.00040878126020590217 -- epoch number 210\n",
      "\n",
      "\n",
      "loss before training is 0.00040873655406231137 -- epoch number 211\n",
      "\n",
      "\n",
      "loss before training is 0.00040869185769711904 -- epoch number 212\n",
      "\n",
      "\n",
      "loss before training is 0.0004086471711065476 -- epoch number 213\n",
      "\n",
      "\n",
      "loss before training is 0.0004086024942879301 -- epoch number 214\n",
      "\n",
      "\n",
      "loss before training is 0.00040855782723782206 -- epoch number 215\n",
      "\n",
      "\n",
      "loss before training is 0.0004085131699528902 -- epoch number 216\n",
      "\n",
      "\n",
      "loss before training is 0.0004084685224300233 -- epoch number 217\n",
      "\n",
      "\n",
      "loss before training is 0.0004084238846661102 -- epoch number 218\n",
      "\n",
      "\n",
      "loss before training is 0.00040837925665803966 -- epoch number 219\n",
      "\n",
      "\n",
      "loss before training is 0.00040833463840236726 -- epoch number 220\n",
      "\n",
      "\n",
      "loss before training is 0.0004082900298960929 -- epoch number 221\n",
      "\n",
      "\n",
      "loss before training is 0.00040824543113577216 -- epoch number 222\n",
      "\n",
      "\n",
      "loss before training is 0.00040820084211851604 -- epoch number 223\n",
      "\n",
      "\n",
      "loss before training is 0.00040815626284088004 -- epoch number 224\n",
      "\n",
      "\n",
      "loss before training is 0.00040811169329997517 -- epoch number 225\n",
      "\n",
      "\n",
      "loss before training is 0.00040806713349213485 -- epoch number 226\n",
      "\n",
      "\n",
      "loss before training is 0.00040802258341447007 -- epoch number 227\n",
      "\n",
      "\n",
      "loss before training is 0.00040797804306398063 -- epoch number 228\n",
      "\n",
      "\n",
      "loss before training is 0.00040793351243700014 -- epoch number 229\n",
      "\n",
      "\n",
      "loss before training is 0.0004078889915309726 -- epoch number 230\n",
      "\n",
      "\n",
      "loss before training is 0.0004078444803422315 -- epoch number 231\n",
      "\n",
      "\n",
      "loss before training is 0.00040779997886777685 -- epoch number 232\n",
      "\n",
      "\n",
      "loss before training is 0.00040775548710427514 -- epoch number 233\n",
      "\n",
      "\n",
      "loss before training is 0.0004077110050487264 -- epoch number 234\n",
      "\n",
      "\n",
      "loss before training is 0.00040766653269768614 -- epoch number 235\n",
      "\n",
      "\n",
      "loss before training is 0.0004076220700484875 -- epoch number 236\n",
      "\n",
      "\n",
      "loss before training is 0.00040757761709746395 -- epoch number 237\n",
      "\n",
      "\n",
      "loss before training is 0.00040753317384172646 -- epoch number 238\n",
      "\n",
      "\n",
      "loss before training is 0.0004074887402779416 -- epoch number 239\n",
      "\n",
      "\n",
      "loss before training is 0.0004074443164032205 -- epoch number 240\n",
      "\n",
      "\n",
      "loss before training is 0.0004073999022138965 -- epoch number 241\n",
      "\n",
      "\n",
      "loss before training is 0.00040735549770719163 -- epoch number 242\n",
      "\n",
      "\n",
      "loss before training is 0.00040731110287966154 -- epoch number 243\n",
      "\n",
      "\n",
      "loss before training is 0.00040726671772863937 -- epoch number 244\n",
      "\n",
      "\n",
      "loss before training is 0.00040722234225045855 -- epoch number 245\n",
      "\n",
      "\n",
      "loss before training is 0.00040717797644200786 -- epoch number 246\n",
      "\n",
      "\n",
      "loss before training is 0.00040713362030039835 -- epoch number 247\n",
      "\n",
      "\n",
      "loss before training is 0.00040708927382229667 -- epoch number 248\n",
      "\n",
      "\n",
      "loss before training is 0.00040704493700436945 -- epoch number 249\n",
      "\n",
      "\n",
      "loss before training is 0.0004070006098439499 -- epoch number 250\n",
      "\n",
      "\n",
      "loss before training is 0.00040695629233781567 -- epoch number 251\n",
      "\n",
      "\n",
      "loss before training is 0.00040691198448207814 -- epoch number 252\n",
      "\n",
      "\n",
      "loss before training is 0.0004068676862742926 -- epoch number 253\n",
      "\n",
      "\n",
      "loss before training is 0.0004068233977112368 -- epoch number 254\n",
      "\n",
      "\n",
      "loss before training is 0.0004067791187894663 -- epoch number 255\n",
      "\n",
      "\n",
      "loss before training is 0.0004067348495062032 -- epoch number 256\n",
      "\n",
      "\n",
      "loss before training is 0.000406690589857892 -- epoch number 257\n",
      "\n",
      "\n",
      "loss before training is 0.00040664633984186584 -- epoch number 258\n",
      "\n",
      "\n",
      "loss before training is 0.0004066020994544582 -- epoch number 259\n",
      "\n",
      "\n",
      "loss before training is 0.00040655786869300223 -- epoch number 260\n",
      "\n",
      "\n",
      "loss before training is 0.0004065136475539425 -- epoch number 261\n",
      "\n",
      "\n",
      "loss before training is 0.000406469436034612 -- epoch number 262\n",
      "\n",
      "\n",
      "loss before training is 0.0004064252341314554 -- epoch number 263\n",
      "\n",
      "\n",
      "loss before training is 0.0004063810418414726 -- epoch number 264\n",
      "\n",
      "\n",
      "loss before training is 0.0004063368591615524 -- epoch number 265\n",
      "\n",
      "\n",
      "loss before training is 0.0004062926860885836 -- epoch number 266\n",
      "\n",
      "\n",
      "loss before training is 0.00040624852261934407 -- epoch number 267\n",
      "\n",
      "\n",
      "loss before training is 0.00040620436875061155 -- epoch number 268\n",
      "\n",
      "\n",
      "loss before training is 0.00040616022447960805 -- epoch number 269\n",
      "\n",
      "\n",
      "loss before training is 0.00040611608980288923 -- epoch number 270\n",
      "\n",
      "\n",
      "loss before training is 0.000406071964717455 -- epoch number 271\n",
      "\n",
      "\n",
      "loss before training is 0.0004060278492201942 -- epoch number 272\n",
      "\n",
      "\n",
      "loss before training is 0.00040598374330799567 -- epoch number 273\n",
      "\n",
      "\n",
      "loss before training is 0.00040593964697752615 -- epoch number 274\n",
      "\n",
      "\n",
      "loss before training is 0.00040589556022589663 -- epoch number 275\n",
      "\n",
      "\n",
      "loss before training is 0.0004058514830499959 -- epoch number 276\n",
      "\n",
      "\n",
      "loss before training is 0.00040580741544649063 -- epoch number 277\n",
      "\n",
      "\n",
      "loss before training is 0.0004057633574127141 -- epoch number 278\n",
      "\n",
      "\n",
      "loss before training is 0.00040571930894477755 -- epoch number 279\n",
      "\n",
      "\n",
      "loss before training is 0.0004056752700403473 -- epoch number 280\n",
      "\n",
      "\n",
      "loss before training is 0.00040563124069586807 -- epoch number 281\n",
      "\n",
      "\n",
      "loss before training is 0.0004055872209081175 -- epoch number 282\n",
      "\n",
      "\n",
      "loss before training is 0.00040554321067453984 -- epoch number 283\n",
      "\n",
      "\n",
      "loss before training is 0.00040549920999169073 -- epoch number 284\n",
      "\n",
      "\n",
      "loss before training is 0.00040545521885634796 -- epoch number 285\n",
      "\n",
      "\n",
      "loss before training is 0.0004054112372654004 -- epoch number 286\n",
      "\n",
      "\n",
      "loss before training is 0.0004053672652160701 -- epoch number 287\n",
      "\n",
      "\n",
      "loss before training is 0.0004053233027049127 -- epoch number 288\n",
      "\n",
      "\n",
      "loss before training is 0.00040527934972903917 -- epoch number 289\n",
      "\n",
      "\n",
      "loss before training is 0.0004052354062853384 -- epoch number 290\n",
      "\n",
      "\n",
      "loss before training is 0.00040519147237047716 -- epoch number 291\n",
      "\n",
      "\n",
      "loss before training is 0.0004051475479816774 -- epoch number 292\n",
      "\n",
      "\n",
      "loss before training is 0.0004051036331154949 -- epoch number 293\n",
      "\n",
      "\n",
      "loss before training is 0.00040505972776904055 -- epoch number 294\n",
      "\n",
      "\n",
      "loss before training is 0.00040501583193942544 -- epoch number 295\n",
      "\n",
      "\n",
      "loss before training is 0.0004049719456230941 -- epoch number 296\n",
      "\n",
      "\n",
      "loss before training is 0.0004049280688172686 -- epoch number 297\n",
      "\n",
      "\n",
      "loss before training is 0.0004048842015187268 -- epoch number 298\n",
      "\n",
      "\n",
      "loss before training is 0.0004048403437248017 -- epoch number 299\n",
      "\n",
      "\n",
      "loss before training is 0.00040479649543138273 -- epoch number 300\n",
      "\n",
      "\n",
      "loss before training is 0.0004047526566368025 -- epoch number 301\n",
      "\n",
      "\n",
      "loss before training is 0.0004047088273363951 -- epoch number 302\n",
      "\n",
      "\n",
      "loss before training is 0.00040466500752849304 -- epoch number 303\n",
      "\n",
      "\n",
      "loss before training is 0.00040462119720931894 -- epoch number 304\n",
      "\n",
      "\n",
      "loss before training is 0.00040457739637553953 -- epoch number 305\n",
      "\n",
      "\n",
      "loss before training is 0.0004045336050248211 -- epoch number 306\n",
      "\n",
      "\n",
      "loss before training is 0.0004044898231533862 -- epoch number 307\n",
      "\n",
      "\n",
      "loss before training is 0.00040444605075878995 -- epoch number 308\n",
      "\n",
      "\n",
      "loss before training is 0.000404402287837366 -- epoch number 309\n",
      "\n",
      "\n",
      "loss before training is 0.00040435853438622544 -- epoch number 310\n",
      "\n",
      "\n",
      "loss before training is 0.00040431479040236803 -- epoch number 311\n",
      "\n",
      "\n",
      "loss before training is 0.0004042710558827939 -- epoch number 312\n",
      "\n",
      "\n",
      "loss before training is 0.0004042273308243917 -- epoch number 313\n",
      "\n",
      "\n",
      "loss before training is 0.0004041836152241616 -- epoch number 314\n",
      "\n",
      "\n",
      "loss before training is 0.0004041399090788813 -- epoch number 315\n",
      "\n",
      "\n",
      "loss before training is 0.0004040962123854397 -- epoch number 316\n",
      "\n",
      "\n",
      "loss before training is 0.0004040525251409478 -- epoch number 317\n",
      "\n",
      "\n",
      "loss before training is 0.0004040088473421834 -- epoch number 318\n",
      "\n",
      "\n",
      "loss before training is 0.0004039651789860354 -- epoch number 319\n",
      "\n",
      "\n",
      "loss before training is 0.0004039215200699481 -- epoch number 320\n",
      "\n",
      "\n",
      "loss before training is 0.0004038778705902549 -- epoch number 321\n",
      "\n",
      "\n",
      "loss before training is 0.00040383423054428906 -- epoch number 322\n",
      "\n",
      "\n",
      "loss before training is 0.0004037905999283841 -- epoch number 323\n",
      "\n",
      "\n",
      "loss before training is 0.0004037469787400953 -- epoch number 324\n",
      "\n",
      "\n",
      "loss before training is 0.00040370336697631153 -- epoch number 325\n",
      "\n",
      "\n",
      "loss before training is 0.0004036597646339217 -- epoch number 326\n",
      "\n",
      "\n",
      "loss before training is 0.0004036161717094815 -- epoch number 327\n",
      "\n",
      "\n",
      "loss before training is 0.00040357258820054626 -- epoch number 328\n",
      "\n",
      "\n",
      "loss before training is 0.0004035290141038937 -- epoch number 329\n",
      "\n",
      "\n",
      "loss before training is 0.0004034854494160796 -- epoch number 330\n",
      "\n",
      "\n",
      "loss before training is 0.00040344189413454813 -- epoch number 331\n",
      "\n",
      "\n",
      "loss before training is 0.00040339834825596613 -- epoch number 332\n",
      "\n",
      "\n",
      "loss before training is 0.0004033548117775556 -- epoch number 333\n",
      "\n",
      "\n",
      "loss before training is 0.00040331128469587224 -- epoch number 334\n",
      "\n",
      "\n",
      "loss before training is 0.0004032677670083603 -- epoch number 335\n",
      "\n",
      "\n",
      "loss before training is 0.00040322425871124236 -- epoch number 336\n",
      "\n",
      "\n",
      "loss before training is 0.0004031807598024068 -- epoch number 337\n",
      "\n",
      "\n",
      "loss before training is 0.0004031372702782983 -- epoch number 338\n",
      "\n",
      "\n",
      "loss before training is 0.00040309379013591686 -- epoch number 339\n",
      "\n",
      "\n",
      "loss before training is 0.0004030503193723734 -- epoch number 340\n",
      "\n",
      "\n",
      "loss before training is 0.00040300685798411265 -- epoch number 341\n",
      "\n",
      "\n",
      "loss before training is 0.00040296340596880095 -- epoch number 342\n",
      "\n",
      "\n",
      "loss before training is 0.0004029199633231051 -- epoch number 343\n",
      "\n",
      "\n",
      "loss before training is 0.0004028765300439139 -- epoch number 344\n",
      "\n",
      "\n",
      "loss before training is 0.0004028331061282275 -- epoch number 345\n",
      "\n",
      "\n",
      "loss before training is 0.0004027896915733788 -- epoch number 346\n",
      "\n",
      "\n",
      "loss before training is 0.0004027462863759238 -- epoch number 347\n",
      "\n",
      "\n",
      "loss before training is 0.00040270289053264015 -- epoch number 348\n",
      "\n",
      "\n",
      "loss before training is 0.00040265950404108327 -- epoch number 349\n",
      "\n",
      "\n",
      "loss before training is 0.0004026161268979198 -- epoch number 350\n",
      "\n",
      "\n",
      "loss before training is 0.00040257275910026086 -- epoch number 351\n",
      "\n",
      "\n",
      "loss before training is 0.00040252940064488434 -- epoch number 352\n",
      "\n",
      "\n",
      "loss before training is 0.00040248605152901225 -- epoch number 353\n",
      "\n",
      "\n",
      "loss before training is 0.00040244271174942245 -- epoch number 354\n",
      "\n",
      "\n",
      "loss before training is 0.000402399381303115 -- epoch number 355\n",
      "\n",
      "\n",
      "loss before training is 0.00040235606018720085 -- epoch number 356\n",
      "\n",
      "\n",
      "loss before training is 0.000402312748398569 -- epoch number 357\n",
      "\n",
      "\n",
      "loss before training is 0.00040226944593433044 -- epoch number 358\n",
      "\n",
      "\n",
      "loss before training is 0.00040222615279137406 -- epoch number 359\n",
      "\n",
      "\n",
      "loss before training is 0.000402182868966811 -- epoch number 360\n",
      "\n",
      "\n",
      "loss before training is 0.000402139594457419 -- epoch number 361\n",
      "\n",
      "\n",
      "loss before training is 0.0004020963292603092 -- epoch number 362\n",
      "\n",
      "\n",
      "loss before training is 0.00040205307337237044 -- epoch number 363\n",
      "\n",
      "\n",
      "loss before training is 0.000402009826791047 -- epoch number 364\n",
      "\n",
      "\n",
      "loss before training is 0.0004019665895126725 -- epoch number 365\n",
      "\n",
      "\n",
      "loss before training is 0.0004019233615345801 -- epoch number 366\n",
      "\n",
      "\n",
      "loss before training is 0.0004018801428538808 -- epoch number 367\n",
      "\n",
      "\n",
      "loss before training is 0.0004018369334672415 -- epoch number 368\n",
      "\n",
      "\n",
      "loss before training is 0.00040179373337210643 -- epoch number 369\n",
      "\n",
      "\n",
      "loss before training is 0.00040175054256503124 -- epoch number 370\n",
      "\n",
      "\n",
      "loss before training is 0.0004017073610434602 -- epoch number 371\n",
      "\n",
      "\n",
      "loss before training is 0.0004016641888039491 -- epoch number 372\n",
      "\n",
      "\n",
      "loss before training is 0.0004016210258439421 -- epoch number 373\n",
      "\n",
      "\n",
      "loss before training is 0.000401577872159884 -- epoch number 374\n",
      "\n",
      "\n",
      "loss before training is 0.00040153472774933 -- epoch number 375\n",
      "\n",
      "\n",
      "loss before training is 0.0004014915926089469 -- epoch number 376\n",
      "\n",
      "\n",
      "loss before training is 0.00040144846673629013 -- epoch number 377\n",
      "\n",
      "\n",
      "loss before training is 0.00040140535012780427 -- epoch number 378\n",
      "\n",
      "\n",
      "loss before training is 0.00040136224278048934 -- epoch number 379\n",
      "\n",
      "\n",
      "loss before training is 0.00040131914469167853 -- epoch number 380\n",
      "\n",
      "\n",
      "loss before training is 0.0004012760558582607 -- epoch number 381\n",
      "\n",
      "\n",
      "loss before training is 0.00040123297627734706 -- epoch number 382\n",
      "\n",
      "\n",
      "loss before training is 0.00040118990594593756 -- epoch number 383\n",
      "\n",
      "\n",
      "loss before training is 0.00040114684486081 -- epoch number 384\n",
      "\n",
      "\n",
      "loss before training is 0.0004011037930192976 -- epoch number 385\n",
      "\n",
      "\n",
      "loss before training is 0.0004010607504179562 -- epoch number 386\n",
      "\n",
      "\n",
      "loss before training is 0.00040101771705445204 -- epoch number 387\n",
      "\n",
      "\n",
      "loss before training is 0.00040097469292545206 -- epoch number 388\n",
      "\n",
      "\n",
      "loss before training is 0.0004009316780278451 -- epoch number 389\n",
      "\n",
      "\n",
      "loss before training is 0.00040088867235918657 -- epoch number 390\n",
      "\n",
      "\n",
      "loss before training is 0.00040084567591581 -- epoch number 391\n",
      "\n",
      "\n",
      "loss before training is 0.00040080268869538193 -- epoch number 392\n",
      "\n",
      "\n",
      "loss before training is 0.00040075971069445797 -- epoch number 393\n",
      "\n",
      "\n",
      "loss before training is 0.0004007167419104824 -- epoch number 394\n",
      "\n",
      "\n",
      "loss before training is 0.00040067378234023317 -- epoch number 395\n",
      "\n",
      "\n",
      "loss before training is 0.0004006308319808213 -- epoch number 396\n",
      "\n",
      "\n",
      "loss before training is 0.0004005878908293579 -- epoch number 397\n",
      "\n",
      "\n",
      "loss before training is 0.00040054495888250976 -- epoch number 398\n",
      "\n",
      "\n",
      "loss before training is 0.0004005020361379433 -- epoch number 399\n",
      "\n",
      "\n",
      "loss before training is 0.0004004591225919921 -- epoch number 400\n",
      "\n",
      "\n",
      "loss before training is 0.0004004162182421005 -- epoch number 401\n",
      "\n",
      "\n",
      "loss before training is 0.00040037332308549064 -- epoch number 402\n",
      "\n",
      "\n",
      "loss before training is 0.00040033043711882926 -- epoch number 403\n",
      "\n",
      "\n",
      "loss before training is 0.00040028756033944963 -- epoch number 404\n",
      "\n",
      "\n",
      "loss before training is 0.0004002446927442407 -- epoch number 405\n",
      "\n",
      "\n",
      "loss before training is 0.0004002018343302025 -- epoch number 406\n",
      "\n",
      "\n",
      "loss before training is 0.00040015898509444613 -- epoch number 407\n",
      "\n",
      "\n",
      "loss before training is 0.0004001161450341937 -- epoch number 408\n",
      "\n",
      "\n",
      "loss before training is 0.000400073314146112 -- epoch number 409\n",
      "\n",
      "\n",
      "loss before training is 0.0004000304924277564 -- epoch number 410\n",
      "\n",
      "\n",
      "loss before training is 0.00039998767987590485 -- epoch number 411\n",
      "\n",
      "\n",
      "loss before training is 0.00039994487648755734 -- epoch number 412\n",
      "\n",
      "\n",
      "loss before training is 0.0003999020822598249 -- epoch number 413\n",
      "\n",
      "\n",
      "loss before training is 0.0003998592971900409 -- epoch number 414\n",
      "\n",
      "\n",
      "loss before training is 0.000399816521274872 -- epoch number 415\n",
      "\n",
      "\n",
      "loss before training is 0.00039977375451109615 -- epoch number 416\n",
      "\n",
      "\n",
      "loss before training is 0.00039973099689682404 -- epoch number 417\n",
      "\n",
      "\n",
      "loss before training is 0.00039968824842805616 -- epoch number 418\n",
      "\n",
      "\n",
      "loss before training is 0.000399645509102681 -- epoch number 419\n",
      "\n",
      "\n",
      "loss before training is 0.00039960277891703215 -- epoch number 420\n",
      "\n",
      "\n",
      "loss before training is 0.00039956005786888723 -- epoch number 421\n",
      "\n",
      "\n",
      "loss before training is 0.0003995173459546908 -- epoch number 422\n",
      "\n",
      "\n",
      "loss before training is 0.00039947464317188725 -- epoch number 423\n",
      "\n",
      "\n",
      "loss before training is 0.0003994319495174766 -- epoch number 424\n",
      "\n",
      "\n",
      "loss before training is 0.00039938926498845885 -- epoch number 425\n",
      "\n",
      "\n",
      "loss before training is 0.00039934658958205616 -- epoch number 426\n",
      "\n",
      "\n",
      "loss before training is 0.0003993039232949354 -- epoch number 427\n",
      "\n",
      "\n",
      "loss before training is 0.00039926126612465187 -- epoch number 428\n",
      "\n",
      "\n",
      "loss before training is 0.00039921861806842783 -- epoch number 429\n",
      "\n",
      "\n",
      "loss before training is 0.0003991759791227079 -- epoch number 430\n",
      "\n",
      "\n",
      "loss before training is 0.00039913334928471435 -- epoch number 431\n",
      "\n",
      "\n",
      "loss before training is 0.00039909072855211355 -- epoch number 432\n",
      "\n",
      "\n",
      "loss before training is 0.00039904811692123907 -- epoch number 433\n",
      "\n",
      "\n",
      "loss before training is 0.0003990055143899796 -- epoch number 434\n",
      "\n",
      "\n",
      "loss before training is 0.00039896292095455767 -- epoch number 435\n",
      "\n",
      "\n",
      "loss before training is 0.00039892033661263965 -- epoch number 436\n",
      "\n",
      "\n",
      "loss before training is 0.00039887776136100355 -- epoch number 437\n",
      "\n",
      "\n",
      "loss before training is 0.0003988351951968715 -- epoch number 438\n",
      "\n",
      "\n",
      "loss before training is 0.0003987926381174657 -- epoch number 439\n",
      "\n",
      "\n",
      "loss before training is 0.0003987500901196751 -- epoch number 440\n",
      "\n",
      "\n",
      "loss before training is 0.000398707551200944 -- epoch number 441\n",
      "\n",
      "\n",
      "loss before training is 0.0003986650213576061 -- epoch number 442\n",
      "\n",
      "\n",
      "loss before training is 0.0003986225005874388 -- epoch number 443\n",
      "\n",
      "\n",
      "loss before training is 0.0003985799888876644 -- epoch number 444\n",
      "\n",
      "\n",
      "loss before training is 0.00039853748625461646 -- epoch number 445\n",
      "\n",
      "\n",
      "loss before training is 0.00039849499268607255 -- epoch number 446\n",
      "\n",
      "\n",
      "loss before training is 0.00039845250817881054 -- epoch number 447\n",
      "\n",
      "\n",
      "loss before training is 0.0003984100327301637 -- epoch number 448\n",
      "\n",
      "\n",
      "loss before training is 0.000398367566337021 -- epoch number 449\n",
      "\n",
      "\n",
      "loss before training is 0.0003983251089966047 -- epoch number 450\n",
      "\n",
      "\n",
      "loss before training is 0.00039828266070580367 -- epoch number 451\n",
      "\n",
      "\n",
      "loss before training is 0.0003982402214620623 -- epoch number 452\n",
      "\n",
      "\n",
      "loss before training is 0.0003981977912621585 -- epoch number 453\n",
      "\n",
      "\n",
      "loss before training is 0.00039815537010353655 -- epoch number 454\n",
      "\n",
      "\n",
      "loss before training is 0.00039811295798308544 -- epoch number 455\n",
      "\n",
      "\n",
      "loss before training is 0.0003980705548980274 -- epoch number 456\n",
      "\n",
      "\n",
      "loss before training is 0.00039802816084514035 -- epoch number 457\n",
      "\n",
      "\n",
      "loss before training is 0.00039798577582209077 -- epoch number 458\n",
      "\n",
      "\n",
      "loss before training is 0.00039794339982576754 -- epoch number 459\n",
      "\n",
      "\n",
      "loss before training is 0.0003979010328530597 -- epoch number 460\n",
      "\n",
      "\n",
      "loss before training is 0.0003978586749013006 -- epoch number 461\n",
      "\n",
      "\n",
      "loss before training is 0.0003978163259674902 -- epoch number 462\n",
      "\n",
      "\n",
      "loss before training is 0.00039777398604896175 -- epoch number 463\n",
      "\n",
      "\n",
      "loss before training is 0.00039773165514282645 -- epoch number 464\n",
      "\n",
      "\n",
      "loss before training is 0.0003976893332458622 -- epoch number 465\n",
      "\n",
      "\n",
      "loss before training is 0.0003976470203557354 -- epoch number 466\n",
      "\n",
      "\n",
      "loss before training is 0.0003976047164687798 -- epoch number 467\n",
      "\n",
      "\n",
      "loss before training is 0.000397562421582995 -- epoch number 468\n",
      "\n",
      "\n",
      "loss before training is 0.0003975201356950479 -- epoch number 469\n",
      "\n",
      "\n",
      "loss before training is 0.00039747785880193856 -- epoch number 470\n",
      "\n",
      "\n",
      "loss before training is 0.0003974355909011113 -- epoch number 471\n",
      "\n",
      "\n",
      "loss before training is 0.0003973933319897883 -- epoch number 472\n",
      "\n",
      "\n",
      "loss before training is 0.0003973510820646365 -- epoch number 473\n",
      "\n",
      "\n",
      "loss before training is 0.0003973088411229891 -- epoch number 474\n",
      "\n",
      "\n",
      "loss before training is 0.0003972666091621794 -- epoch number 475\n",
      "\n",
      "\n",
      "loss before training is 0.0003972243861793185 -- epoch number 476\n",
      "\n",
      "\n",
      "loss before training is 0.00039718217217118437 -- epoch number 477\n",
      "\n",
      "\n",
      "loss before training is 0.0003971399671352213 -- epoch number 478\n",
      "\n",
      "\n",
      "loss before training is 0.00039709777106854057 -- epoch number 479\n",
      "\n",
      "\n",
      "loss before training is 0.00039705558396814207 -- epoch number 480\n",
      "\n",
      "\n",
      "loss before training is 0.0003970134058315813 -- epoch number 481\n",
      "\n",
      "\n",
      "loss before training is 0.00039697123665563615 -- epoch number 482\n",
      "\n",
      "\n",
      "loss before training is 0.0003969290764374178 -- epoch number 483\n",
      "\n",
      "\n",
      "loss before training is 0.00039688692517414844 -- epoch number 484\n",
      "\n",
      "\n",
      "loss before training is 0.00039684478286271713 -- epoch number 485\n",
      "\n",
      "\n",
      "loss before training is 0.0003968026495010124 -- epoch number 486\n",
      "\n",
      "\n",
      "loss before training is 0.000396760525085479 -- epoch number 487\n",
      "\n",
      "\n",
      "loss before training is 0.0003967184096135614 -- epoch number 488\n",
      "\n",
      "\n",
      "loss before training is 0.0003966763030825927 -- epoch number 489\n",
      "\n",
      "\n",
      "loss before training is 0.00039663420548912884 -- epoch number 490\n",
      "\n",
      "\n",
      "loss before training is 0.0003965921168307252 -- epoch number 491\n",
      "\n",
      "\n",
      "loss before training is 0.000396550037104715 -- epoch number 492\n",
      "\n",
      "\n",
      "loss before training is 0.00039650796630809836 -- epoch number 493\n",
      "\n",
      "\n",
      "loss before training is 0.00039646590443776435 -- epoch number 494\n",
      "\n",
      "\n",
      "loss before training is 0.00039642385149093513 -- epoch number 495\n",
      "\n",
      "\n",
      "loss before training is 0.00039638180746516614 -- epoch number 496\n",
      "\n",
      "\n",
      "loss before training is 0.0003963397723573463 -- epoch number 497\n",
      "\n",
      "\n",
      "loss before training is 0.00039629774616492015 -- epoch number 498\n",
      "\n",
      "\n",
      "loss before training is 0.0003962557288843323 -- epoch number 499\n",
      "\n",
      "\n",
      "loss before training is 0.00039621372051336037 -- epoch number 500\n",
      "\n",
      "\n",
      "loss before training is 0.00039617172104900437 -- epoch number 501\n",
      "\n",
      "\n",
      "loss before training is 0.0003961297304887087 -- epoch number 502\n",
      "\n",
      "\n",
      "loss before training is 0.00039608774882947346 -- epoch number 503\n",
      "\n",
      "\n",
      "loss before training is 0.0003960457760678545 -- epoch number 504\n",
      "\n",
      "\n",
      "loss before training is 0.0003960038122019625 -- epoch number 505\n",
      "\n",
      "\n",
      "loss before training is 0.00039596185722857546 -- epoch number 506\n",
      "\n",
      "\n",
      "loss before training is 0.00039591991114447134 -- epoch number 507\n",
      "\n",
      "\n",
      "loss before training is 0.0003958779739475387 -- epoch number 508\n",
      "\n",
      "\n",
      "loss before training is 0.00039583604563444457 -- epoch number 509\n",
      "\n",
      "\n",
      "loss before training is 0.00039579412620285533 -- epoch number 510\n",
      "\n",
      "\n",
      "loss before training is 0.0003957522156494379 -- epoch number 511\n",
      "\n",
      "\n",
      "loss before training is 0.0003957103139715256 -- epoch number 512\n",
      "\n",
      "\n",
      "loss before training is 0.00039566842116634063 -- epoch number 513\n",
      "\n",
      "\n",
      "loss before training is 0.00039562653723099417 -- epoch number 514\n",
      "\n",
      "\n",
      "loss before training is 0.00039558466216293054 -- epoch number 515\n",
      "\n",
      "\n",
      "loss before training is 0.00039554279595903883 -- epoch number 516\n",
      "\n",
      "\n",
      "loss before training is 0.0003955009386167634 -- epoch number 517\n",
      "\n",
      "\n",
      "loss before training is 0.0003954590901328822 -- epoch number 518\n",
      "\n",
      "\n",
      "loss before training is 0.0003954172505050617 -- epoch number 519\n",
      "\n",
      "\n",
      "loss before training is 0.0003953754197304131 -- epoch number 520\n",
      "\n",
      "\n",
      "loss before training is 0.0003953335978058254 -- epoch number 521\n",
      "\n",
      "\n",
      "loss before training is 0.00039529178472863194 -- epoch number 522\n",
      "\n",
      "\n",
      "loss before training is 0.0003952499804959439 -- epoch number 523\n",
      "\n",
      "\n",
      "loss before training is 0.0003952081851053167 -- epoch number 524\n",
      "\n",
      "\n",
      "loss before training is 0.0003951663985534172 -- epoch number 525\n",
      "\n",
      "\n",
      "loss before training is 0.0003951246208378009 -- epoch number 526\n",
      "\n",
      "\n",
      "loss before training is 0.00039508285195557894 -- epoch number 527\n",
      "\n",
      "\n",
      "loss before training is 0.0003950410919041957 -- epoch number 528\n",
      "\n",
      "\n",
      "loss before training is 0.000394999340680207 -- epoch number 529\n",
      "\n",
      "\n",
      "loss before training is 0.00039495759828127937 -- epoch number 530\n",
      "\n",
      "\n",
      "loss before training is 0.00039491586470463507 -- epoch number 531\n",
      "\n",
      "\n",
      "loss before training is 0.0003948741399477184 -- epoch number 532\n",
      "\n",
      "\n",
      "loss before training is 0.00039483242400697424 -- epoch number 533\n",
      "\n",
      "\n",
      "loss before training is 0.0003947907168801801 -- epoch number 534\n",
      "\n",
      "\n",
      "loss before training is 0.0003947490185644472 -- epoch number 535\n",
      "\n",
      "\n",
      "loss before training is 0.0003947073290571088 -- epoch number 536\n",
      "\n",
      "\n",
      "loss before training is 0.0003946656483549429 -- epoch number 537\n",
      "\n",
      "\n",
      "loss before training is 0.00039462397645539384 -- epoch number 538\n",
      "\n",
      "\n",
      "loss before training is 0.000394582313355795 -- epoch number 539\n",
      "\n",
      "\n",
      "loss before training is 0.00039454065905336866 -- epoch number 540\n",
      "\n",
      "\n",
      "loss before training is 0.0003944990135451148 -- epoch number 541\n",
      "\n",
      "\n",
      "loss before training is 0.0003944573768281447 -- epoch number 542\n",
      "\n",
      "\n",
      "loss before training is 0.00039441574890023594 -- epoch number 543\n",
      "\n",
      "\n",
      "loss before training is 0.00039437412975816647 -- epoch number 544\n",
      "\n",
      "\n",
      "loss before training is 0.0003943325193993807 -- epoch number 545\n",
      "\n",
      "\n",
      "loss before training is 0.0003942909178207677 -- epoch number 546\n",
      "\n",
      "\n",
      "loss before training is 0.0003942493250197718 -- epoch number 547\n",
      "\n",
      "\n",
      "loss before training is 0.00039420774099361525 -- epoch number 548\n",
      "\n",
      "\n",
      "loss before training is 0.00039416616573952035 -- epoch number 549\n",
      "\n",
      "\n",
      "loss before training is 0.0003941245992547093 -- epoch number 550\n",
      "\n",
      "\n",
      "loss before training is 0.0003940830415362934 -- epoch number 551\n",
      "\n",
      "\n",
      "loss before training is 0.00039404149258193903 -- epoch number 552\n",
      "\n",
      "\n",
      "loss before training is 0.00039399995238798 -- epoch number 553\n",
      "\n",
      "\n",
      "loss before training is 0.0003939584209525271 -- epoch number 554\n",
      "\n",
      "\n",
      "loss before training is 0.00039391689827246933 -- epoch number 555\n",
      "\n",
      "\n",
      "loss before training is 0.000393875384345029 -- epoch number 556\n",
      "\n",
      "\n",
      "loss before training is 0.00039383387916765053 -- epoch number 557\n",
      "\n",
      "\n",
      "loss before training is 0.0003937923827372229 -- epoch number 558\n",
      "\n",
      "\n",
      "loss before training is 0.0003937508950510795 -- epoch number 559\n",
      "\n",
      "\n",
      "loss before training is 0.00039370941610644255 -- epoch number 560\n",
      "\n",
      "\n",
      "loss before training is 0.00039366794590086756 -- epoch number 561\n",
      "\n",
      "\n",
      "loss before training is 0.0003936264844310214 -- epoch number 562\n",
      "\n",
      "\n",
      "loss before training is 0.00039358503169501484 -- epoch number 563\n",
      "\n",
      "\n",
      "loss before training is 0.0003935435876889596 -- epoch number 564\n",
      "\n",
      "\n",
      "loss before training is 0.0003935021524109664 -- epoch number 565\n",
      "\n",
      "\n",
      "loss before training is 0.0003934607258581464 -- epoch number 566\n",
      "\n",
      "\n",
      "loss before training is 0.00039341930802705557 -- epoch number 567\n",
      "\n",
      "\n",
      "loss before training is 0.0003933778989158047 -- epoch number 568\n",
      "\n",
      "\n",
      "loss before training is 0.0003933364985213938 -- epoch number 569\n",
      "\n",
      "\n",
      "loss before training is 0.00039329510684115625 -- epoch number 570\n",
      "\n",
      "\n",
      "loss before training is 0.00039325372387175907 -- epoch number 571\n",
      "\n",
      "\n",
      "loss before training is 0.00039321234961120196 -- epoch number 572\n",
      "\n",
      "\n",
      "loss before training is 0.0003931709840562629 -- epoch number 573\n",
      "\n",
      "\n",
      "loss before training is 0.0003931296272043863 -- epoch number 574\n",
      "\n",
      "\n",
      "loss before training is 0.0003930882790526833 -- epoch number 575\n",
      "\n",
      "\n",
      "loss before training is 0.0003930469395987095 -- epoch number 576\n",
      "\n",
      "\n",
      "loss before training is 0.00039300560883946494 -- epoch number 577\n",
      "\n",
      "\n",
      "loss before training is 0.0003929642867718388 -- epoch number 578\n",
      "\n",
      "\n",
      "loss before training is 0.00039292297339394176 -- epoch number 579\n",
      "\n",
      "\n",
      "loss before training is 0.0003928816687024408 -- epoch number 580\n",
      "\n",
      "\n",
      "loss before training is 0.00039284037269478035 -- epoch number 581\n",
      "\n",
      "\n",
      "loss before training is 0.0003927990853684049 -- epoch number 582\n",
      "\n",
      "\n",
      "loss before training is 0.0003927578067203144 -- epoch number 583\n",
      "\n",
      "\n",
      "loss before training is 0.0003927165367473981 -- epoch number 584\n",
      "\n",
      "\n",
      "loss before training is 0.00039267527544776674 -- epoch number 585\n",
      "\n",
      "\n",
      "loss before training is 0.0003926340228181983 -- epoch number 586\n",
      "\n",
      "\n",
      "loss before training is 0.0003925927788560262 -- epoch number 587\n",
      "\n",
      "\n",
      "loss before training is 0.0003925515435584727 -- epoch number 588\n",
      "\n",
      "\n",
      "loss before training is 0.00039251031692276006 -- epoch number 589\n",
      "\n",
      "\n",
      "loss before training is 0.0003924690989463327 -- epoch number 590\n",
      "\n",
      "\n",
      "loss before training is 0.00039242788962641284 -- epoch number 591\n",
      "\n",
      "\n",
      "loss before training is 0.000392386688960445 -- epoch number 592\n",
      "\n",
      "\n",
      "loss before training is 0.0003923454969454293 -- epoch number 593\n",
      "\n",
      "\n",
      "loss before training is 0.000392304313578588 -- epoch number 594\n",
      "\n",
      "\n",
      "loss before training is 0.00039226313885736556 -- epoch number 595\n",
      "\n",
      "\n",
      "loss before training is 0.0003922219727790953 -- epoch number 596\n",
      "\n",
      "\n",
      "loss before training is 0.00039218081534077737 -- epoch number 597\n",
      "\n",
      "\n",
      "loss before training is 0.0003921396665400783 -- epoch number 598\n",
      "\n",
      "\n",
      "loss before training is 0.00039209852637410935 -- epoch number 599\n",
      "\n",
      "\n",
      "loss before training is 0.00039205739483998175 -- epoch number 600\n",
      "\n",
      "\n",
      "loss before training is 0.000392016271935251 -- epoch number 601\n",
      "\n",
      "\n",
      "loss before training is 0.00039197515765691717 -- epoch number 602\n",
      "\n",
      "\n",
      "loss before training is 0.00039193405200253583 -- epoch number 603\n",
      "\n",
      "\n",
      "loss before training is 0.0003918929549693292 -- epoch number 604\n",
      "\n",
      "\n",
      "loss before training is 0.0003918518665544086 -- epoch number 605\n",
      "\n",
      "\n",
      "loss before training is 0.0003918107867554405 -- epoch number 606\n",
      "\n",
      "\n",
      "loss before training is 0.00039176971556920305 -- epoch number 607\n",
      "\n",
      "\n",
      "loss before training is 0.00039172865299336266 -- epoch number 608\n",
      "\n",
      "\n",
      "loss before training is 0.00039168759902503063 -- epoch number 609\n",
      "\n",
      "\n",
      "loss before training is 0.0003916465536618735 -- epoch number 610\n",
      "\n",
      "\n",
      "loss before training is 0.0003916055169005583 -- epoch number 611\n",
      "\n",
      "\n",
      "loss before training is 0.0003915644887388625 -- epoch number 612\n",
      "\n",
      "\n",
      "loss before training is 0.0003915234691740086 -- epoch number 613\n",
      "\n",
      "\n",
      "loss before training is 0.0003914824582029966 -- epoch number 614\n",
      "\n",
      "\n",
      "loss before training is 0.0003914414558234932 -- epoch number 615\n",
      "\n",
      "\n",
      "loss before training is 0.00039140046203260946 -- epoch number 616\n",
      "\n",
      "\n",
      "loss before training is 0.00039135947682756786 -- epoch number 617\n",
      "\n",
      "\n",
      "loss before training is 0.0003913185002060349 -- epoch number 618\n",
      "\n",
      "\n",
      "loss before training is 0.00039127753216501067 -- epoch number 619\n",
      "\n",
      "\n",
      "loss before training is 0.00039123657270205076 -- epoch number 620\n",
      "\n",
      "\n",
      "loss before training is 0.00039119562181371103 -- epoch number 621\n",
      "\n",
      "\n",
      "loss before training is 0.0003911546794983245 -- epoch number 622\n",
      "\n",
      "\n",
      "loss before training is 0.00039111374575255813 -- epoch number 623\n",
      "\n",
      "\n",
      "loss before training is 0.0003910728205740784 -- epoch number 624\n",
      "\n",
      "\n",
      "loss before training is 0.00039103190395999666 -- epoch number 625\n",
      "\n",
      "\n",
      "loss before training is 0.0003909909959074241 -- epoch number 626\n",
      "\n",
      "\n",
      "loss before training is 0.0003909500964141383 -- epoch number 627\n",
      "\n",
      "\n",
      "loss before training is 0.0003909092054771396 -- epoch number 628\n",
      "\n",
      "\n",
      "loss before training is 0.00039086832309376116 -- epoch number 629\n",
      "\n",
      "\n",
      "loss before training is 0.0003908274492613365 -- epoch number 630\n",
      "\n",
      "\n",
      "loss before training is 0.0003907865839774211 -- epoch number 631\n",
      "\n",
      "\n",
      "loss before training is 0.00039074572723912625 -- epoch number 632\n",
      "\n",
      "\n",
      "loss before training is 0.0003907048790437852 -- epoch number 633\n",
      "\n",
      "\n",
      "loss before training is 0.0003906640393883982 -- epoch number 634\n",
      "\n",
      "\n",
      "loss before training is 0.00039062320827085395 -- epoch number 635\n",
      "\n",
      "\n",
      "loss before training is 0.00039058238568826377 -- epoch number 636\n",
      "\n",
      "\n",
      "loss before training is 0.0003905415716378498 -- epoch number 637\n",
      "\n",
      "\n",
      "loss before training is 0.00039050076611683453 -- epoch number 638\n",
      "\n",
      "\n",
      "loss before training is 0.0003904599691229955 -- epoch number 639\n",
      "\n",
      "\n",
      "loss before training is 0.0003904191806532219 -- epoch number 640\n",
      "\n",
      "\n",
      "loss before training is 0.00039037840070506915 -- epoch number 641\n",
      "\n",
      "\n",
      "loss before training is 0.00039033762927575963 -- epoch number 642\n",
      "\n",
      "\n",
      "loss before training is 0.0003902968663627378 -- epoch number 643\n",
      "\n",
      "\n",
      "loss before training is 0.0003902561119631149 -- epoch number 644\n",
      "\n",
      "\n",
      "loss before training is 0.00039021536607455746 -- epoch number 645\n",
      "\n",
      "\n",
      "loss before training is 0.0003901746286938436 -- epoch number 646\n",
      "\n",
      "\n",
      "loss before training is 0.00039013389981897305 -- epoch number 647\n",
      "\n",
      "\n",
      "loss before training is 0.0003900931794470571 -- epoch number 648\n",
      "\n",
      "\n",
      "loss before training is 0.0003900524675754291 -- epoch number 649\n",
      "\n",
      "\n",
      "loss before training is 0.00039001176420097827 -- epoch number 650\n",
      "\n",
      "\n",
      "loss before training is 0.00038997106932181535 -- epoch number 651\n",
      "\n",
      "\n",
      "loss before training is 0.00038993038293449626 -- epoch number 652\n",
      "\n",
      "\n",
      "loss before training is 0.00038988970503724303 -- epoch number 653\n",
      "\n",
      "\n",
      "loss before training is 0.0003898490356268336 -- epoch number 654\n",
      "\n",
      "\n",
      "loss before training is 0.0003898083747001572 -- epoch number 655\n",
      "\n",
      "\n",
      "loss before training is 0.0003897677222557689 -- epoch number 656\n",
      "\n",
      "\n",
      "loss before training is 0.00038972707829000244 -- epoch number 657\n",
      "\n",
      "\n",
      "loss before training is 0.00038968644280041345 -- epoch number 658\n",
      "\n",
      "\n",
      "loss before training is 0.00038964581578455735 -- epoch number 659\n",
      "\n",
      "\n",
      "loss before training is 0.0003896051972398787 -- epoch number 660\n",
      "\n",
      "\n",
      "loss before training is 0.0003895645871634887 -- epoch number 661\n",
      "\n",
      "\n",
      "loss before training is 0.0003895239855529429 -- epoch number 662\n",
      "\n",
      "\n",
      "loss before training is 0.00038948339240557465 -- epoch number 663\n",
      "\n",
      "\n",
      "loss before training is 0.00038944280771793994 -- epoch number 664\n",
      "\n",
      "\n",
      "loss before training is 0.00038940223148870495 -- epoch number 665\n",
      "\n",
      "\n",
      "loss before training is 0.0003893616637144256 -- epoch number 666\n",
      "\n",
      "\n",
      "loss before training is 0.0003893211043927685 -- epoch number 667\n",
      "\n",
      "\n",
      "loss before training is 0.00038928055352062277 -- epoch number 668\n",
      "\n",
      "\n",
      "loss before training is 0.0003892400110960993 -- epoch number 669\n",
      "\n",
      "\n",
      "loss before training is 0.000389199477115754 -- epoch number 670\n",
      "\n",
      "\n",
      "loss before training is 0.00038915895157769773 -- epoch number 671\n",
      "\n",
      "\n",
      "loss before training is 0.00038911843447870853 -- epoch number 672\n",
      "\n",
      "\n",
      "loss before training is 0.00038907792581623096 -- epoch number 673\n",
      "\n",
      "\n",
      "loss before training is 0.0003890374255881537 -- epoch number 674\n",
      "\n",
      "\n",
      "loss before training is 0.00038899693379147694 -- epoch number 675\n",
      "\n",
      "\n",
      "loss before training is 0.0003889564504235341 -- epoch number 676\n",
      "\n",
      "\n",
      "loss before training is 0.00038891597548143644 -- epoch number 677\n",
      "\n",
      "\n",
      "loss before training is 0.0003888755089629617 -- epoch number 678\n",
      "\n",
      "\n",
      "loss before training is 0.0003888350508654432 -- epoch number 679\n",
      "\n",
      "\n",
      "loss before training is 0.0003887946011859922 -- epoch number 680\n",
      "\n",
      "\n",
      "loss before training is 0.00038875415992227534 -- epoch number 681\n",
      "\n",
      "\n",
      "loss before training is 0.0003887137270717372 -- epoch number 682\n",
      "\n",
      "\n",
      "loss before training is 0.0003886733026311557 -- epoch number 683\n",
      "\n",
      "\n",
      "loss before training is 0.0003886328865987528 -- epoch number 684\n",
      "\n",
      "\n",
      "loss before training is 0.00038859247897097345 -- epoch number 685\n",
      "\n",
      "\n",
      "loss before training is 0.00038855207974603954 -- epoch number 686\n",
      "\n",
      "\n",
      "loss before training is 0.0003885116889207292 -- epoch number 687\n",
      "\n",
      "\n",
      "loss before training is 0.00038847130649293107 -- epoch number 688\n",
      "\n",
      "\n",
      "loss before training is 0.0003884309324596455 -- epoch number 689\n",
      "\n",
      "\n",
      "loss before training is 0.0003883905668186501 -- epoch number 690\n",
      "\n",
      "\n",
      "loss before training is 0.0003883502095665008 -- epoch number 691\n",
      "\n",
      "\n",
      "loss before training is 0.00038830986070164167 -- epoch number 692\n",
      "\n",
      "\n",
      "loss before training is 0.00038826952022085083 -- epoch number 693\n",
      "\n",
      "\n",
      "loss before training is 0.0003882291881214617 -- epoch number 694\n",
      "\n",
      "\n",
      "loss before training is 0.0003881888644010298 -- epoch number 695\n",
      "\n",
      "\n",
      "loss before training is 0.0003881485490569996 -- epoch number 696\n",
      "\n",
      "\n",
      "loss before training is 0.0003881082420868157 -- epoch number 697\n",
      "\n",
      "\n",
      "loss before training is 0.00038806794348770026 -- epoch number 698\n",
      "\n",
      "\n",
      "loss before training is 0.0003880276532568758 -- epoch number 699\n",
      "\n",
      "\n",
      "loss before training is 0.0003879873713922309 -- epoch number 700\n",
      "\n",
      "\n",
      "loss before training is 0.0003879470978909881 -- epoch number 701\n",
      "\n",
      "\n",
      "loss before training is 0.0003879068327501475 -- epoch number 702\n",
      "\n",
      "\n",
      "loss before training is 0.0003878665759673758 -- epoch number 703\n",
      "\n",
      "\n",
      "loss before training is 0.0003878263275403395 -- epoch number 704\n",
      "\n",
      "\n",
      "loss before training is 0.00038778608746603896 -- epoch number 705\n",
      "\n",
      "\n",
      "loss before training is 0.0003877458557423628 -- epoch number 706\n",
      "\n",
      "\n",
      "loss before training is 0.00038770563236586715 -- epoch number 707\n",
      "\n",
      "\n",
      "loss before training is 0.00038766541733466274 -- epoch number 708\n",
      "\n",
      "\n",
      "loss before training is 0.00038762521064608304 -- epoch number 709\n",
      "\n",
      "\n",
      "loss before training is 0.00038758501229712835 -- epoch number 710\n",
      "\n",
      "\n",
      "loss before training is 0.0003875448222860205 -- epoch number 711\n",
      "\n",
      "\n",
      "loss before training is 0.00038750464060909344 -- epoch number 712\n",
      "\n",
      "\n",
      "loss before training is 0.000387464467264569 -- epoch number 713\n",
      "\n",
      "\n",
      "loss before training is 0.0003874243022495586 -- epoch number 714\n",
      "\n",
      "\n",
      "loss before training is 0.0003873841455615067 -- epoch number 715\n",
      "\n",
      "\n",
      "loss before training is 0.00038734399719774664 -- epoch number 716\n",
      "\n",
      "\n",
      "loss before training is 0.000387303857155612 -- epoch number 717\n",
      "\n",
      "\n",
      "loss before training is 0.00038726372543276924 -- epoch number 718\n",
      "\n",
      "\n",
      "loss before training is 0.00038722360202655194 -- epoch number 719\n",
      "\n",
      "\n",
      "loss before training is 0.00038718348693429343 -- epoch number 720\n",
      "\n",
      "\n",
      "loss before training is 0.00038714338015366045 -- epoch number 721\n",
      "\n",
      "\n",
      "loss before training is 0.00038710328168154205 -- epoch number 722\n",
      "\n",
      "\n",
      "loss before training is 0.00038706319151604916 -- epoch number 723\n",
      "\n",
      "\n",
      "loss before training is 0.000387023109654182 -- epoch number 724\n",
      "\n",
      "\n",
      "loss before training is 0.00038698303609316305 -- epoch number 725\n",
      "\n",
      "\n",
      "loss before training is 0.00038694297083076987 -- epoch number 726\n",
      "\n",
      "\n",
      "loss before training is 0.000386902913864336 -- epoch number 727\n",
      "\n",
      "\n",
      "loss before training is 0.0003868628651914169 -- epoch number 728\n",
      "\n",
      "\n",
      "loss before training is 0.000386822824809124 -- epoch number 729\n",
      "\n",
      "\n",
      "loss before training is 0.00038678279271490165 -- epoch number 730\n",
      "\n",
      "\n",
      "loss before training is 0.00038674276890652773 -- epoch number 731\n",
      "\n",
      "\n",
      "loss before training is 0.00038670275338133556 -- epoch number 732\n",
      "\n",
      "\n",
      "loss before training is 0.00038666274613654753 -- epoch number 733\n",
      "\n",
      "\n",
      "loss before training is 0.0003866227471696082 -- epoch number 734\n",
      "\n",
      "\n",
      "loss before training is 0.0003865827564781841 -- epoch number 735\n",
      "\n",
      "\n",
      "loss before training is 0.0003865427740592756 -- epoch number 736\n",
      "\n",
      "\n",
      "loss before training is 0.0003865027999109935 -- epoch number 737\n",
      "\n",
      "\n",
      "loss before training is 0.000386462834030116 -- epoch number 738\n",
      "\n",
      "\n",
      "loss before training is 0.00038642287641442067 -- epoch number 739\n",
      "\n",
      "\n",
      "loss before training is 0.00038638292706113007 -- epoch number 740\n",
      "\n",
      "\n",
      "loss before training is 0.00038634298596791075 -- epoch number 741\n",
      "\n",
      "\n",
      "loss before training is 0.0003863030531322072 -- epoch number 742\n",
      "\n",
      "\n",
      "loss before training is 0.00038626312855146393 -- epoch number 743\n",
      "\n",
      "\n",
      "loss before training is 0.00038622321222268126 -- epoch number 744\n",
      "\n",
      "\n",
      "loss before training is 0.000386183304143859 -- epoch number 745\n",
      "\n",
      "\n",
      "loss before training is 0.0003861434043119973 -- epoch number 746\n",
      "\n",
      "\n",
      "loss before training is 0.00038610351272487406 -- epoch number 747\n",
      "\n",
      "\n",
      "loss before training is 0.00038606362938026684 -- epoch number 748\n",
      "\n",
      "\n",
      "loss before training is 0.0003860237542746206 -- epoch number 749\n",
      "\n",
      "\n",
      "loss before training is 0.0003859838874060463 -- epoch number 750\n",
      "\n",
      "\n",
      "loss before training is 0.00038594402877187734 -- epoch number 751\n",
      "\n",
      "\n",
      "loss before training is 0.0003859041783696693 -- epoch number 752\n",
      "\n",
      "\n",
      "loss before training is 0.00038586433619664456 -- epoch number 753\n",
      "\n",
      "\n",
      "loss before training is 0.00038582450225035876 -- epoch number 754\n",
      "\n",
      "\n",
      "loss before training is 0.0003857846765284785 -- epoch number 755\n",
      "\n",
      "\n",
      "loss before training is 0.0003857448590281151 -- epoch number 756\n",
      "\n",
      "\n",
      "loss before training is 0.00038570504974693527 -- epoch number 757\n",
      "\n",
      "\n",
      "loss before training is 0.0003856652486822724 -- epoch number 758\n",
      "\n",
      "\n",
      "loss before training is 0.00038562545583190424 -- epoch number 759\n",
      "\n",
      "\n",
      "loss before training is 0.00038558567119283105 -- epoch number 760\n",
      "\n",
      "\n",
      "loss before training is 0.0003855458947626084 -- epoch number 761\n",
      "\n",
      "\n",
      "loss before training is 0.000385506126539014 -- epoch number 762\n",
      "\n",
      "\n",
      "loss before training is 0.00038546636651904813 -- epoch number 763\n",
      "\n",
      "\n",
      "loss before training is 0.0003854266147003775 -- epoch number 764\n",
      "\n",
      "\n",
      "loss before training is 0.0003853868710807797 -- epoch number 765\n",
      "\n",
      "\n",
      "loss before training is 0.0003853471356572551 -- epoch number 766\n",
      "\n",
      "\n",
      "loss before training is 0.0003853074084274703 -- epoch number 767\n",
      "\n",
      "\n",
      "loss before training is 0.00038526768938898097 -- epoch number 768\n",
      "\n",
      "\n",
      "loss before training is 0.00038522797853900946 -- epoch number 769\n",
      "\n",
      "\n",
      "loss before training is 0.00038518827587533344 -- epoch number 770\n",
      "\n",
      "\n",
      "loss before training is 0.00038514858139528644 -- epoch number 771\n",
      "\n",
      "\n",
      "loss before training is 0.00038510889509609083 -- epoch number 772\n",
      "\n",
      "\n",
      "loss before training is 0.0003850692169756354 -- epoch number 773\n",
      "\n",
      "\n",
      "loss before training is 0.0003850295470308094 -- epoch number 774\n",
      "\n",
      "\n",
      "loss before training is 0.00038498988525983475 -- epoch number 775\n",
      "\n",
      "\n",
      "loss before training is 0.00038495023165982284 -- epoch number 776\n",
      "\n",
      "\n",
      "loss before training is 0.0003849105862281071 -- epoch number 777\n",
      "\n",
      "\n",
      "loss before training is 0.00038487094896224314 -- epoch number 778\n",
      "\n",
      "\n",
      "loss before training is 0.0003848313198598976 -- epoch number 779\n",
      "\n",
      "\n",
      "loss before training is 0.0003847916989182929 -- epoch number 780\n",
      "\n",
      "\n",
      "loss before training is 0.00038475208613520686 -- epoch number 781\n",
      "\n",
      "\n",
      "loss before training is 0.00038471248150775066 -- epoch number 782\n",
      "\n",
      "\n",
      "loss before training is 0.00038467288503370216 -- epoch number 783\n",
      "\n",
      "\n",
      "loss before training is 0.0003846332967102837 -- epoch number 784\n",
      "\n",
      "\n",
      "loss before training is 0.00038459371653549513 -- epoch number 785\n",
      "\n",
      "\n",
      "loss before training is 0.00038455414450611465 -- epoch number 786\n",
      "\n",
      "\n",
      "loss before training is 0.0003845145806202532 -- epoch number 787\n",
      "\n",
      "\n",
      "loss before training is 0.00038447502487491095 -- epoch number 788\n",
      "\n",
      "\n",
      "loss before training is 0.0003844354772678657 -- epoch number 789\n",
      "\n",
      "\n",
      "loss before training is 0.00038439593779667316 -- epoch number 790\n",
      "\n",
      "\n",
      "loss before training is 0.00038435640645844446 -- epoch number 791\n",
      "\n",
      "\n",
      "loss before training is 0.0003843168832509575 -- epoch number 792\n",
      "\n",
      "\n",
      "loss before training is 0.00038427736817165677 -- epoch number 793\n",
      "\n",
      "\n",
      "loss before training is 0.0003842378612180979 -- epoch number 794\n",
      "\n",
      "\n",
      "loss before training is 0.0003841983623876143 -- epoch number 795\n",
      "\n",
      "\n",
      "loss before training is 0.00038415887167787274 -- epoch number 796\n",
      "\n",
      "\n",
      "loss before training is 0.00038411938908642875 -- epoch number 797\n",
      "\n",
      "\n",
      "loss before training is 0.0003840799146102827 -- epoch number 798\n",
      "\n",
      "\n",
      "loss before training is 0.0003840404482475454 -- epoch number 799\n",
      "\n",
      "\n",
      "loss before training is 0.0003840009899952172 -- epoch number 800\n",
      "\n",
      "\n",
      "loss before training is 0.00038396153985129804 -- epoch number 801\n",
      "\n",
      "\n",
      "loss before training is 0.00038392209781301027 -- epoch number 802\n",
      "\n",
      "\n",
      "loss before training is 0.0003838826638777984 -- epoch number 803\n",
      "\n",
      "\n",
      "loss before training is 0.0003838432380432181 -- epoch number 804\n",
      "\n",
      "\n",
      "loss before training is 0.00038380382030693604 -- epoch number 805\n",
      "\n",
      "\n",
      "loss before training is 0.0003837644106660635 -- epoch number 806\n",
      "\n",
      "\n",
      "loss before training is 0.00038372500911860053 -- epoch number 807\n",
      "\n",
      "\n",
      "loss before training is 0.0003836856156616583 -- epoch number 808\n",
      "\n",
      "\n",
      "loss before training is 0.0003836462302930147 -- epoch number 809\n",
      "\n",
      "\n",
      "loss before training is 0.0003836068530103363 -- epoch number 810\n",
      "\n",
      "\n",
      "loss before training is 0.00038356748381029025 -- epoch number 811\n",
      "\n",
      "\n",
      "loss before training is 0.0003835281226913207 -- epoch number 812\n",
      "\n",
      "\n",
      "loss before training is 0.00038348876965053896 -- epoch number 813\n",
      "\n",
      "\n",
      "loss before training is 0.00038344942468561177 -- epoch number 814\n",
      "\n",
      "\n",
      "loss before training is 0.0003834100877937615 -- epoch number 815\n",
      "\n",
      "\n",
      "loss before training is 0.000383370758972877 -- epoch number 816\n",
      "\n",
      "\n",
      "loss before training is 0.0003833314382199586 -- epoch number 817\n",
      "\n",
      "\n",
      "loss before training is 0.0003832921255332282 -- epoch number 818\n",
      "\n",
      "\n",
      "loss before training is 0.0003832528209095751 -- epoch number 819\n",
      "\n",
      "\n",
      "loss before training is 0.00038321352434699923 -- epoch number 820\n",
      "\n",
      "\n",
      "loss before training is 0.0003831742358426119 -- epoch number 821\n",
      "\n",
      "\n",
      "loss before training is 0.0003831349553941909 -- epoch number 822\n",
      "\n",
      "\n",
      "loss before training is 0.0003830956829994028 -- epoch number 823\n",
      "\n",
      "\n",
      "loss before training is 0.00038305641865502596 -- epoch number 824\n",
      "\n",
      "\n",
      "loss before training is 0.00038301716235939333 -- epoch number 825\n",
      "\n",
      "\n",
      "loss before training is 0.0003829779141096163 -- epoch number 826\n",
      "\n",
      "\n",
      "loss before training is 0.0003829386739038058 -- epoch number 827\n",
      "\n",
      "\n",
      "loss before training is 0.000382899441738629 -- epoch number 828\n",
      "\n",
      "\n",
      "loss before training is 0.00038286021761219677 -- epoch number 829\n",
      "\n",
      "\n",
      "loss before training is 0.0003828210015218427 -- epoch number 830\n",
      "\n",
      "\n",
      "loss before training is 0.0003827817934650113 -- epoch number 831\n",
      "\n",
      "\n",
      "loss before training is 0.0003827425934394803 -- epoch number 832\n",
      "\n",
      "\n",
      "loss before training is 0.0003827034014425833 -- epoch number 833\n",
      "\n",
      "\n",
      "loss before training is 0.00038266421747187586 -- epoch number 834\n",
      "\n",
      "\n",
      "loss before training is 0.0003826250415250247 -- epoch number 835\n",
      "\n",
      "\n",
      "loss before training is 0.0003825858735992522 -- epoch number 836\n",
      "\n",
      "\n",
      "loss before training is 0.0003825467136926694 -- epoch number 837\n",
      "\n",
      "\n",
      "loss before training is 0.0003825075618023876 -- epoch number 838\n",
      "\n",
      "\n",
      "loss before training is 0.0003824684179259625 -- epoch number 839\n",
      "\n",
      "\n",
      "loss before training is 0.0003824292820609497 -- epoch number 840\n",
      "\n",
      "\n",
      "loss before training is 0.0003823901542049048 -- epoch number 841\n",
      "\n",
      "\n",
      "loss before training is 0.00038235103435538346 -- epoch number 842\n",
      "\n",
      "\n",
      "loss before training is 0.00038231192250994135 -- epoch number 843\n",
      "\n",
      "\n",
      "loss before training is 0.00038227281866635624 -- epoch number 844\n",
      "\n",
      "\n",
      "loss before training is 0.00038223372282173947 -- epoch number 845\n",
      "\n",
      "\n",
      "loss before training is 0.00038219463497375774 -- epoch number 846\n",
      "\n",
      "\n",
      "loss before training is 0.0003821555551202999 -- epoch number 847\n",
      "\n",
      "\n",
      "loss before training is 0.00038211648325847734 -- epoch number 848\n",
      "\n",
      "\n",
      "loss before training is 0.0003820774193860678 -- epoch number 849\n",
      "\n",
      "\n",
      "loss before training is 0.00038203836350051584 -- epoch number 850\n",
      "\n",
      "\n",
      "loss before training is 0.0003819993155994882 -- epoch number 851\n",
      "\n",
      "\n",
      "loss before training is 0.00038196027568042953 -- epoch number 852\n",
      "\n",
      "\n",
      "loss before training is 0.00038192124374100635 -- epoch number 853\n",
      "\n",
      "\n",
      "loss before training is 0.0003818822197786634 -- epoch number 854\n",
      "\n",
      "\n",
      "loss before training is 0.00038184320379106734 -- epoch number 855\n",
      "\n",
      "\n",
      "loss before training is 0.0003818041957753295 -- epoch number 856\n",
      "\n",
      "\n",
      "loss before training is 0.00038176519572989415 -- epoch number 857\n",
      "\n",
      "\n",
      "loss before training is 0.00038172620365165043 -- epoch number 858\n",
      "\n",
      "\n",
      "loss before training is 0.00038168721953826514 -- epoch number 859\n",
      "\n",
      "\n",
      "loss before training is 0.000381648243387516 -- epoch number 860\n",
      "\n",
      "\n",
      "loss before training is 0.00038160927519640336 -- epoch number 861\n",
      "\n",
      "\n",
      "loss before training is 0.00038157031496292707 -- epoch number 862\n",
      "\n",
      "\n",
      "loss before training is 0.000381531362684865 -- epoch number 863\n",
      "\n",
      "\n",
      "loss before training is 0.0003814924183595506 -- epoch number 864\n",
      "\n",
      "\n",
      "loss before training is 0.00038145348198431744 -- epoch number 865\n",
      "\n",
      "\n",
      "loss before training is 0.00038141455355683216 -- epoch number 866\n",
      "\n",
      "\n",
      "loss before training is 0.0003813756330749837 -- epoch number 867\n",
      "\n",
      "\n",
      "loss before training is 0.00038133672053621654 -- epoch number 868\n",
      "\n",
      "\n",
      "loss before training is 0.00038129781593775324 -- epoch number 869\n",
      "\n",
      "\n",
      "loss before training is 0.0003812589192775936 -- epoch number 870\n",
      "\n",
      "\n",
      "loss before training is 0.00038122003055284914 -- epoch number 871\n",
      "\n",
      "\n",
      "loss before training is 0.00038118114976185284 -- epoch number 872\n",
      "\n",
      "\n",
      "loss before training is 0.00038114227690116086 -- epoch number 873\n",
      "\n",
      "\n",
      "loss before training is 0.0003811034119691063 -- epoch number 874\n",
      "\n",
      "\n",
      "loss before training is 0.0003810645549630226 -- epoch number 875\n",
      "\n",
      "\n",
      "loss before training is 0.00038102570588046547 -- epoch number 876\n",
      "\n",
      "\n",
      "loss before training is 0.00038098686471910165 -- epoch number 877\n",
      "\n",
      "\n",
      "loss before training is 0.0003809480314764868 -- epoch number 878\n",
      "\n",
      "\n",
      "loss before training is 0.00038090920614995444 -- epoch number 879\n",
      "\n",
      "\n",
      "loss before training is 0.0003808703887376155 -- epoch number 880\n",
      "\n",
      "\n",
      "loss before training is 0.0003808315792366925 -- epoch number 881\n",
      "\n",
      "\n",
      "loss before training is 0.00038079277764463003 -- epoch number 882\n",
      "\n",
      "\n",
      "loss before training is 0.00038075398395920584 -- epoch number 883\n",
      "\n",
      "\n",
      "loss before training is 0.0003807151981779756 -- epoch number 884\n",
      "\n",
      "\n",
      "loss before training is 0.000380676420298495 -- epoch number 885\n",
      "\n",
      "\n",
      "loss before training is 0.00038063765031854177 -- epoch number 886\n",
      "\n",
      "\n",
      "loss before training is 0.0003805988882353385 -- epoch number 887\n",
      "\n",
      "\n",
      "loss before training is 0.00038056013404677385 -- epoch number 888\n",
      "\n",
      "\n",
      "loss before training is 0.00038052138775040366 -- epoch number 889\n",
      "\n",
      "\n",
      "loss before training is 0.0003804826493438946 -- epoch number 890\n",
      "\n",
      "\n",
      "loss before training is 0.0003804439188244691 -- epoch number 891\n",
      "\n",
      "\n",
      "loss before training is 0.000380405196189905 -- epoch number 892\n",
      "\n",
      "\n",
      "loss before training is 0.00038036648143798007 -- epoch number 893\n",
      "\n",
      "\n",
      "loss before training is 0.00038032777456624997 -- epoch number 894\n",
      "\n",
      "\n",
      "loss before training is 0.00038028907557193723 -- epoch number 895\n",
      "\n",
      "\n",
      "loss before training is 0.00038025038445304167 -- epoch number 896\n",
      "\n",
      "\n",
      "loss before training is 0.00038021170120700797 -- epoch number 897\n",
      "\n",
      "\n",
      "loss before training is 0.0003801730258315029 -- epoch number 898\n",
      "\n",
      "\n",
      "loss before training is 0.00038013435832408196 -- epoch number 899\n",
      "\n",
      "\n",
      "loss before training is 0.00038009569868241205 -- epoch number 900\n",
      "\n",
      "\n",
      "loss before training is 0.00038005704690360453 -- epoch number 901\n",
      "\n",
      "\n",
      "loss before training is 0.00038001840298621464 -- epoch number 902\n",
      "\n",
      "\n",
      "loss before training is 0.00037997976692702055 -- epoch number 903\n",
      "\n",
      "\n",
      "loss before training is 0.0003799411387240223 -- epoch number 904\n",
      "\n",
      "\n",
      "loss before training is 0.00037990251837466437 -- epoch number 905\n",
      "\n",
      "\n",
      "loss before training is 0.00037986390587639146 -- epoch number 906\n",
      "\n",
      "\n",
      "loss before training is 0.00037982530122731455 -- epoch number 907\n",
      "\n",
      "\n",
      "loss before training is 0.000379786704424434 -- epoch number 908\n",
      "\n",
      "\n",
      "loss before training is 0.00037974811546586073 -- epoch number 909\n",
      "\n",
      "\n",
      "loss before training is 0.0003797095343490394 -- epoch number 910\n",
      "\n",
      "\n",
      "loss before training is 0.0003796709610716368 -- epoch number 911\n",
      "\n",
      "\n",
      "loss before training is 0.00037963239563109746 -- epoch number 912\n",
      "\n",
      "\n",
      "loss before training is 0.000379593838024866 -- epoch number 913\n",
      "\n",
      "\n",
      "loss before training is 0.00037955528825105346 -- epoch number 914\n",
      "\n",
      "\n",
      "loss before training is 0.0003795167463068823 -- epoch number 915\n",
      "\n",
      "\n",
      "loss before training is 0.00037947821219035246 -- epoch number 916\n",
      "\n",
      "\n",
      "loss before training is 0.0003794396858985754 -- epoch number 917\n",
      "\n",
      "\n",
      "loss before training is 0.00037940116742943985 -- epoch number 918\n",
      "\n",
      "\n",
      "loss before training is 0.00037936265678083485 -- epoch number 919\n",
      "\n",
      "\n",
      "loss before training is 0.00037932415394976066 -- epoch number 920\n",
      "\n",
      "\n",
      "loss before training is 0.00037928565893421723 -- epoch number 921\n",
      "\n",
      "\n",
      "loss before training is 0.0003792471717319824 -- epoch number 922\n",
      "\n",
      "\n",
      "loss before training is 0.00037920869234038974 -- epoch number 923\n",
      "\n",
      "\n",
      "loss before training is 0.000379170220757217 -- epoch number 924\n",
      "\n",
      "\n",
      "loss before training is 0.0003791317569799088 -- epoch number 925\n",
      "\n",
      "\n",
      "loss before training is 0.000379093301006243 -- epoch number 926\n",
      "\n",
      "\n",
      "loss before training is 0.0003790548528336642 -- epoch number 927\n",
      "\n",
      "\n",
      "loss before training is 0.00037901641246017233 -- epoch number 928\n",
      "\n",
      "\n",
      "loss before training is 0.00037897797988310094 -- epoch number 929\n",
      "\n",
      "\n",
      "loss before training is 0.0003789395551000057 -- epoch number 930\n",
      "\n",
      "\n",
      "loss before training is 0.0003789011381085534 -- epoch number 931\n",
      "\n",
      "\n",
      "loss before training is 0.0003788627289070772 -- epoch number 932\n",
      "\n",
      "\n",
      "loss before training is 0.000378824327491911 -- epoch number 933\n",
      "\n",
      "\n",
      "loss before training is 0.00037878593386161014 -- epoch number 934\n",
      "\n",
      "\n",
      "loss before training is 0.00037874754801373023 -- epoch number 935\n",
      "\n",
      "\n",
      "loss before training is 0.00037870916994549384 -- epoch number 936\n",
      "\n",
      "\n",
      "loss before training is 0.0003786707996549009 -- epoch number 937\n",
      "\n",
      "\n",
      "loss before training is 0.0003786324371396181 -- epoch number 938\n",
      "\n",
      "\n",
      "loss before training is 0.00037859408239675695 -- epoch number 939\n",
      "\n",
      "\n",
      "loss before training is 0.0003785557354247616 -- epoch number 940\n",
      "\n",
      "\n",
      "loss before training is 0.00037851739622074353 -- epoch number 941\n",
      "\n",
      "\n",
      "loss before training is 0.0003784790647825916 -- epoch number 942\n",
      "\n",
      "\n",
      "loss before training is 0.00037844074110752833 -- epoch number 943\n",
      "\n",
      "\n",
      "loss before training is 0.0003784024251933315 -- epoch number 944\n",
      "\n",
      "\n",
      "loss before training is 0.0003783641170382232 -- epoch number 945\n",
      "\n",
      "\n",
      "loss before training is 0.00037832581663887067 -- epoch number 946\n",
      "\n",
      "\n",
      "loss before training is 0.00037828752399371804 -- epoch number 947\n",
      "\n",
      "\n",
      "loss before training is 0.00037824923910043204 -- epoch number 948\n",
      "\n",
      "\n",
      "loss before training is 0.00037821096195612427 -- epoch number 949\n",
      "\n",
      "\n",
      "loss before training is 0.0003781726925587945 -- epoch number 950\n",
      "\n",
      "\n",
      "loss before training is 0.0003781344309057764 -- epoch number 951\n",
      "\n",
      "\n",
      "loss before training is 0.00037809617699506993 -- epoch number 952\n",
      "\n",
      "\n",
      "loss before training is 0.00037805793082434176 -- epoch number 953\n",
      "\n",
      "\n",
      "loss before training is 0.0003780196923907035 -- epoch number 954\n",
      "\n",
      "\n",
      "loss before training is 0.000377981461692377 -- epoch number 955\n",
      "\n",
      "\n",
      "loss before training is 0.00037794323872725134 -- epoch number 956\n",
      "\n",
      "\n",
      "loss before training is 0.00037790502349199366 -- epoch number 957\n",
      "\n",
      "\n",
      "loss before training is 0.0003778668159850481 -- epoch number 958\n",
      "\n",
      "\n",
      "loss before training is 0.0003778286162038594 -- epoch number 959\n",
      "\n",
      "\n",
      "loss before training is 0.0003777904241462053 -- epoch number 960\n",
      "\n",
      "\n",
      "loss before training is 0.0003777522398096416 -- epoch number 961\n",
      "\n",
      "\n",
      "loss before training is 0.00037771406319139073 -- epoch number 962\n",
      "\n",
      "\n",
      "loss before training is 0.0003776758942897859 -- epoch number 963\n",
      "\n",
      "\n",
      "loss before training is 0.00037763773310238273 -- epoch number 964\n",
      "\n",
      "\n",
      "loss before training is 0.00037759957962629276 -- epoch number 965\n",
      "\n",
      "\n",
      "loss before training is 0.0003775614338598491 -- epoch number 966\n",
      "\n",
      "\n",
      "loss before training is 0.00037752329580049634 -- epoch number 967\n",
      "\n",
      "\n",
      "loss before training is 0.00037748516544556816 -- epoch number 968\n",
      "\n",
      "\n",
      "loss before training is 0.0003774470427932866 -- epoch number 969\n",
      "\n",
      "\n",
      "loss before training is 0.00037740892784087415 -- epoch number 970\n",
      "\n",
      "\n",
      "loss before training is 0.0003773708205863308 -- epoch number 971\n",
      "\n",
      "\n",
      "loss before training is 0.00037733272102699015 -- epoch number 972\n",
      "\n",
      "\n",
      "loss before training is 0.00037729462916074105 -- epoch number 973\n",
      "\n",
      "\n",
      "loss before training is 0.0003772565449850282 -- epoch number 974\n",
      "\n",
      "\n",
      "loss before training is 0.00037721846849774046 -- epoch number 975\n",
      "\n",
      "\n",
      "loss before training is 0.0003771803996968778 -- epoch number 976\n",
      "\n",
      "\n",
      "loss before training is 0.00037714233857944065 -- epoch number 977\n",
      "\n",
      "\n",
      "loss before training is 0.0003771042851433178 -- epoch number 978\n",
      "\n",
      "\n",
      "loss before training is 0.0003770662393862873 -- epoch number 979\n",
      "\n",
      "\n",
      "loss before training is 0.0003770282013061268 -- epoch number 980\n",
      "\n",
      "\n",
      "loss before training is 0.000376990170900281 -- epoch number 981\n",
      "\n",
      "\n",
      "loss before training is 0.00037695214816652777 -- epoch number 982\n",
      "\n",
      "\n",
      "loss before training is 0.0003769141331026449 -- epoch number 983\n",
      "\n",
      "\n",
      "loss before training is 0.00037687612570629927 -- epoch number 984\n",
      "\n",
      "\n",
      "loss before training is 0.0003768381259750465 -- epoch number 985\n",
      "\n",
      "\n",
      "loss before training is 0.0003768001339065534 -- epoch number 986\n",
      "\n",
      "\n",
      "loss before training is 0.0003767621494985978 -- epoch number 987\n",
      "\n",
      "\n",
      "loss before training is 0.00037672417274884647 -- epoch number 988\n",
      "\n",
      "\n",
      "loss before training is 0.0003766862036548552 -- epoch number 989\n",
      "\n",
      "\n",
      "loss before training is 0.00037664824221462384 -- epoch number 990\n",
      "\n",
      "\n",
      "loss before training is 0.00037661028842548606 -- epoch number 991\n",
      "\n",
      "\n",
      "loss before training is 0.0003765723422853308 -- epoch number 992\n",
      "\n",
      "\n",
      "loss before training is 0.00037653440379193585 -- epoch number 993\n",
      "\n",
      "\n",
      "loss before training is 0.0003764964729425238 -- epoch number 994\n",
      "\n",
      "\n",
      "loss before training is 0.00037645854973531666 -- epoch number 995\n",
      "\n",
      "\n",
      "loss before training is 0.00037642063416775914 -- epoch number 996\n",
      "\n",
      "\n",
      "loss before training is 0.0003763827262376291 -- epoch number 997\n",
      "\n",
      "\n",
      "loss before training is 0.00037634482594248224 -- epoch number 998\n",
      "\n",
      "\n",
      "loss before training is 0.0003763069332802075 -- epoch number 999\n",
      "\n",
      "\n",
      "loss before training is 0.0003762690482482495 -- epoch number 1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "#------------------------------------------Forward Propagation-------------------------------------------------\n",
    "    \n",
    "    in_hidden_1 = w1.dot(x) + b1\n",
    "    out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "    in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "    out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "    in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "    y_hat = softmax(in_output_layer)\n",
    "    \n",
    "    loss = cross_E(y, y_hat)\n",
    "    print(f'loss before training is {loss} -- epoch number {epoch + 1}')\n",
    "    print('\\n')\n",
    "    \n",
    "#-----------------------------------------Gradient Calculations via Back Propagation---------------------------\n",
    "\n",
    "    error_upto_softmax = np.sum(cross_E_grad(y, y_hat) * softmax_dash(in_output_layer), axis = 0).reshape((-1, 1))\n",
    "    \n",
    "    grad_w3 = error_upto_softmax .dot( out_hidden_2.T )\n",
    "    \n",
    "    grad_b3 = error_upto_softmax\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    \n",
    "    error_grad_upto_H2 = np.sum(error_upto_softmax * w3, axis = 0) .reshape((-1, 1))\n",
    "    \n",
    "    error_upto_softmax_H2 = np.sum(error_grad_upto_H2 * softmax_dash(in_hidden_2), axis = 0).reshape((-1, 1))\n",
    "    \n",
    "    grad_w2 = error_upto_softmax_H2 .dot( out_hidden_1.T )\n",
    "    \n",
    "    grad_b2 = error_upto_softmax_H2\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    \n",
    "    error_grad_upto_H1 = np.sum(error_upto_softmax_H2 * w2, axis = 0) .reshape((-1, 1))\n",
    "    \n",
    "    grad_w1 = error_grad_upto_H1 * sig_dash(in_hidden_1) .dot( x.T )\n",
    "    \n",
    "    grad_b1 = error_grad_upto_H1 * sig_dash(in_hidden_1)\n",
    "    \n",
    "#-----------------------------------------Updating weights and biases via SGD Momentum------------------------\n",
    "\n",
    "    update_w1 = - learning_rate * grad_w1 + momentum * update_w1\n",
    "    w1 += update_w1\n",
    "    \n",
    "    update_b1 = - learning_rate * grad_b1 + momentum * update_b1\n",
    "    b1 += update_b1\n",
    "    \n",
    "    update_w2 = - learning_rate * grad_w2 + momentum * update_w2\n",
    "    w2 += update_w2\n",
    "    \n",
    "    update_b2 = - learning_rate * grad_b2 + momentum * update_b2\n",
    "    b2 += update_b2\n",
    "    \n",
    "    update_w3 = - learning_rate * grad_w3 + momentum * update_w3\n",
    "    w3 += update_w3\n",
    "    \n",
    "    update_b3 = - learning_rate * grad_b3 + momentum * update_b3\n",
    "    b3 += update_b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-philippines",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-belief",
   "metadata": {},
   "source": [
    "**Forward feed after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "inner-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00119462],\n",
       "       [0.99603257],\n",
       "       [0.00138686],\n",
       "       [0.00138594]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "burning-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dying-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038433545161639282"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f257f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe975d092d2ac7f937a42acc0742499e035d25a93da4137fa8ab0db54717d31f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
